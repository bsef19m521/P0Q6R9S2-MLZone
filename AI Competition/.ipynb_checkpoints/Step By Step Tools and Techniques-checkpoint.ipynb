{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26ea7ab4",
   "metadata": {},
   "source": [
    "## Data Science / Machine Learning / AI Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903aabe7",
   "metadata": {},
   "source": [
    "## 1. Problem Statement\n",
    "- Regression\n",
    "- Classification\n",
    "- Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75f215",
   "metadata": {},
   "source": [
    "## 2. Data Gathering\n",
    "- Kaggle\n",
    "- Web Scraping\n",
    "- Google Sheets\n",
    "- Google Drive\n",
    "-  Cloud\n",
    "- Database\n",
    "- API\n",
    "- Datawarehouse\n",
    "- Data Lake\n",
    "\n",
    "**Note:** In PUCON, we will provide data through Cloud. On the other hand, In softec, data will be provided through Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc70aa8f",
   "metadata": {},
   "source": [
    "## 3. Data Exploration and Understanding\n",
    "- **Explore**: Features, Distributions, Relationships\n",
    "- **EDA**: Identify patterns, Outliers, Opportunities for Feature Engineering\n",
    "- **Feature Importance**: \n",
    "    - **Plots**\n",
    "    - **Permutation Importance(Method 1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e401df",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and Data Cleaning\n",
    "- **Missing Values**: Mean, Median, Mode, KNN, Random Forest, Neural Network\n",
    "- **Outliers**: Z-score, IQR, Robust Scaler, Capping, Winsorization\n",
    "- **Data Inconsistence Values**: Correction of data-types\n",
    "- **Imbalance Classes**: SMOTE, Undersampling majority Classes, Oversampling minority classes\n",
    "- **Stratified Sampling**: Stratified KFold, Stratified ShuffleSplit( Ensure randomness and representation of proportions classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967efe6",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "- **Feature Scaling**: MinMaxScaler, RobustScaler, ZScore Normalization (Standardize features by removing the mean and scaling to unit variance)\n",
    "- **Feature Encoding**: Ordinal Encoding, One-Hot Encoding, Label Encoding, Frequency Encoding, Textual data encoding for NLP Problems(Tokenization,Removal of stopwords, Stemming, Lemmatization, Bag of Words, TF-IDF ,Count Vectorization, Embedding)\n",
    "- **Dimensionality Reduction**: PCA, LDA(to improve model efficiency and prevent overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c8fe0",
   "metadata": {},
   "source": [
    "### Tips for Feature Engineering\n",
    "- **Feature Discretization**: Convert numerical features into discrete bins(Intervals).\n",
    "- **Feature Selection**: \n",
    "    - **Statistical Methods/Techniques**: Chi-Squared, Mutual Information\n",
    "    - **Wrapper Methods**: Genetic Algorithm, SelectKBest\n",
    "    - **Embedded Methods**: Lasso regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e4ad3",
   "metadata": {},
   "source": [
    "## 6. Data Validation and Data Leakage\n",
    "- **Split data:** Training(For Model training), Validation(For Model validation), Testing(For Model testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d644a2b5",
   "metadata": {},
   "source": [
    "## 7. Model Building\n",
    "- **Algorithms**: Logistic Regression, Decision Tree, Random Forest, XGBoost, Linear Regression, SVM, Neural Network, KNN, Navies Bayes\n",
    "- **Ensemble Methods**: Bagging, Boosting, stacking\n",
    "- **Libraries**: Sklearn(Machine Learning), XGBoost, LightGBM, CatBoost, TensorFlow, PyTorch, Keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 8. Model Evaluation\n",
    "- **Metrics**: Accuracy, Precision, Recall, F1-score, Confusion Matrix, ROC curve, AUC, Precision-Recall Curve, Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "\n",
    "\n",
    "**Note**: Experimentation is key to improve model performance.\n",
    "\n",
    "\n",
    "### Factors to consider when choosing a model\n",
    "- **Dataset Size and Complexity**:\n",
    "- **Interpretability Requirements**: Random Forest, Decisiion Tree\n",
    "- **Computational Resources**: CPU , GPU(Neural Network)\n",
    "- **Speed and Accuracy**: Speed, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46afef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Hyperparameter Tuning\n",
    "## 10. Model Explainability and Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f061cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "- **Feature Selection**: Variance Threshold, SelectKBest, SelectFromModel, RFE, RFECV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
