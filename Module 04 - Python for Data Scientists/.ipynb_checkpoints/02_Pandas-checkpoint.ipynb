{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6686c3f",
   "metadata": {},
   "source": [
    "<img src=\"images/pandas-intro.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc3b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b694ef9",
   "metadata": {},
   "source": [
    "# _Python_Pandas_Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091eff40",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"700\" height=\"700\"  src=\"images/pandas-apps.png\"  >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb7cba",
   "metadata": {},
   "source": [
    "> **Pandas is an open source python library built on top of numpy and provides easy to use data structures and data analysis tools. Pandas has derived its name from panel data system and was developed by wes mckinney in 2008.**\n",
    "\n",
    "> **Data scientists use pandas for performing various data science tasks starting from downloading, opening, reading and writing files of different file formats like csv, excel, json, html and so on. They load the data set into its data structure called data frame.**\n",
    "\n",
    "> **A Pandas Dataframe is a 2-dimensional labeled data structure (like SQL table) with heterogeneously typed columns, having both a row and a column index.**\n",
    "\n",
    "> **After the data is loaded in a data frame the data scientists perform a various data manipulation tasks like filtering and modifying data based on multiple conditions cutting, splitting, merging, sorting, scaling, pivoting and aggregating of data.**\n",
    "\n",
    "> **Data cleaning is done to enhance the data accuracy and integrity by identifying and removing null values, duplicates and outliers.**\n",
    "\n",
    "> **Data wrangling actually transforms the data structurally to appropriate format and makes it ready to be used by the machine learning engineers so that they can apply appropriate machine learning models or algorithm on that data set for training validating and testing purposes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38583d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "930e2e5c",
   "metadata": {},
   "source": [
    "# Learning Agenda of this Notebook:\n",
    "- What is Pandas and how is it used in AI?\n",
    "- Key features of Pandas\n",
    "- Data Types in Pandas\n",
    "- What does Pandas deal with?\n",
    "\n",
    "- Creating Series in Pandas\n",
    "    - From Python List\n",
    "    - From NumPy Arrays\n",
    "    - From Python Dictionary\n",
    "    - From a scalar value\n",
    "    - Creating empty series object\n",
    "- Attributes of a Pandas Series\n",
    "- Arithmetic Operations on Series\n",
    "\n",
    "- Dataframes in Pandas\n",
    "    - Anatomy of a Dataframe\n",
    "    - Creating Dataframe\n",
    "        - An empty dataframe\n",
    "        - Two-Dimensional NumPy Array\n",
    "        - Dictionary of Python Lists\n",
    "        - Dictionary of Panda Series\n",
    "    - Attributes of a Dataframe\n",
    "    - Bonus\n",
    "- Data Handling with Pandas\n",
    "  - Practice Exercise I\n",
    "  - Practice Exercise II\n",
    "- All Statistical functions in Pandas\n",
    "- Input/Output Operations\n",
    "- Aggregation & Grouping\n",
    "  - Practice Exercise\n",
    "- Merging, Joining and Concatenation\n",
    "  - Practice Exercise\n",
    "- How To Perform Data Visualization with Pandas\n",
    "- Exercise I\n",
    "- Exercise II\n",
    "- Pandas's Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae90f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93d7fe9d",
   "metadata": {},
   "source": [
    "### Data Structures in Pandas:\n",
    "<img src=\"https://www.databricks.com/wp-content/uploads/2019/03/pandas1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f11cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d881437",
   "metadata": {},
   "source": [
    ">-  **A Pandas Dataframe is a 2-dimensional labeled data structure (like SQL table) with heterogeneously typed columns, having both a row and a column index.**\n",
    ">-  **In short Pandas is a Software Libarary in Computer Programming and it is written for the Python Programming Language its work to do `data analysis and manipulation.`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a611a7",
   "metadata": {},
   "source": [
    "## So, what is Pandas and how is it used in AI?\n",
    "\n",
    "Artificial Intelligence is about executing machine learning algorithms on products that we use every day. Any ML algorithm, for it to be effective, needs the following prerequisite steps to be done.\n",
    "- `Data Collection` – Conducting opinion Surveys, scraping the internet, etc.\n",
    "- `Data Handling` – Viewing data as a table, performing cleaning activities like checking for spellings, removal of blanks and wrong cases, removal of invalid values from data, etc.\n",
    "- `Data Visualization` – plotting appealing graphs, so anyone who looks at the data can know what story the data tells us.\n",
    "- `Pandas` – short for `Panel Data` (A panel is a 3D container of data) – is a library in python which contains in-built functions to clean, transform, manipulate, visualize and analyze data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d09ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4573e9",
   "metadata": {},
   "source": [
    "## Key Features of Pandas\n",
    "<img src=\"images/Python-Pandas-Features.webp\" height=600px width=600px>\n",
    "\n",
    "\n",
    "- It has a fast and efficient DataFrame object with the default and customized indexing.\n",
    "- Used for reshaping and pivoting of the data sets.\n",
    "- Group by data for aggregations and transformations.\n",
    "- It is used for data alignment and integration of the missing data.\n",
    "- Provide the functionality of Time Series.\n",
    "- Process a variety of data sets in different formats like matrix data, tabular heterogeneous, time series.\n",
    "- Handle multiple operations of the data sets such as subsetting, slicing, filtering, groupBy, re-ordering, and re-shaping.\n",
    "- It integrates with the other libraries such as SciPy, and scikit-learn.\n",
    "- Provides fast performance, and If you want to speed it, even more, you can use the Cython."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ceb96",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "A data type is used by a programming language to understand how to store and manipulate data.\n",
    "- `int` : Integer number, eg: 10, 12\n",
    "- `float` : Floating point number, eg: 100.2, 3.1415\n",
    "- `bool` : True/False value\n",
    "- `object` : Test, non-numeric, or a combination of text and non-numeric values, eg: Apple\n",
    "- `DateTime` : Date and time values\n",
    "- `category` : A finite list of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb38f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "092dbfa8",
   "metadata": {},
   "source": [
    "## What does Pandas deal with?\n",
    "There are two major categories of data that you can come across while doing data analysis.\n",
    "- One dimensional data\n",
    "- Two-dimensional data\n",
    "\n",
    "These data can be of any data type. Character, number or even an object.\n",
    "\n",
    "> **Series in Pandas is one-dimensional data, and data frames are 2-dimensional data. A series can hold only a single data type, whereas a data frame is meant to contain more than one data type.**\n",
    "\n",
    "![](images/dataframe.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6983313",
   "metadata": {},
   "source": [
    "**In the example shown above, `Name` is a `series` and it is of the datatype – `Object` and it is treated as a character array. `Age` is another series and it is of the type – `Integer`. Third is the `Marks` is the third series and it is of the type `Integer` again.  The individual Series are one dimensional and hold only one data type. However, the `dataframe` as a whole contains more than 2 dimensions and is `heterogeneous` in nature.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a267b9",
   "metadata": {},
   "source": [
    "# Creating Series & data frames in python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466edb52",
   "metadata": {},
   "source": [
    "## Creating a simple Serie\n",
    "\n",
    "\n",
    "<img align=\"right\" width=\"500\" height=\"600\"  src=\"images/series-anatomy.png\"  >\n",
    "\n",
    "> **A Series is a one-dimensional array capable of holding a sequence of values of any data type (integers, floating point numbers, strings, Python objects etc) which by default have numeric data labels starting from zero. You can imagine a Pandas Series as a column in a spreadsheet or a Pandas Dataframe object.**\n",
    "- To create a Series object you can use `pd.Series()` method\n",
    "\n",
    "**```pd.Series(data, index, dtype, name)```**\n",
    "- Where,\n",
    "   - `data`: can be a Python list, Python dictionary, numPy array, or a scalar value.\n",
    "   - `index`: If you donot pass the index argument, it will default to `np.arrange(n)`. Indices must be hashable (numbers or strings) and have the same length as `data`. Non-unique index values are allowed. Index is used for three purposes:\n",
    "       - Identification.\n",
    "       - Selection.\n",
    "       - Alignment.\n",
    "   - `dtype`: Optionally, you can assign any valid numpy datatype to the series object (np.sctypes). If not specified, this will be inferred from `data`.\n",
    "   - `name`: Optionally, you can assign a name to a series, which becomes attribute of the series object. Moreover, it becomes the column name, if that series object is used to create a dataframe later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bc5e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae19831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.5.3', ['/home/dell/.local/lib/python3.8/site-packages/pandas'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__, pd.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230e8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe886b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "499bb65b",
   "metadata": {},
   "source": [
    "### a. Creating a Series from Python List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40266a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['Ehtisham', 'Ali', 'Ayesha', '','Dua']  # note the empty string\n",
    "\n",
    "# When index is not provided, it creates an index for the data starting from zero and with a step size of one.\n",
    "s = pd.Series(data=list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f4c56ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Ehtisham\n",
      "1         Ali\n",
      "2      Ayesha\n",
      "3            \n",
      "4         Dua\n",
      "dtype: object\n",
      "\n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(s)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e20229",
   "metadata": {},
   "source": [
    "> Observe that output is shown in two columns - the `index` is on the left and the `data value` is on the right. If we do not explicitly specify an index for the data values while creating a series, then by default indices range from `0` through `N – 1`. Here N is the number of data elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68b32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c5d8f6f",
   "metadata": {},
   "source": [
    "**You can explicitly specify the index for a Series object, which can be either int or string type, and must be of the same size as the values in the series. Otherwise, it will raise a ValueError**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c595cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['Ehtisham', 'Ali', 'Ayesha', 'Dua']\n",
    "indices = ['01', '02', '', '02']   # non-unique index values are allowed and you can have empty string as index\n",
    "\n",
    "s = pd.Series(data=list1, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e5945f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01    Ehtisham\n",
      "02         Ali\n",
      "        Ayesha\n",
      "02         Dua\n",
      "dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(s)\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718a8fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "02    Ali\n",
       "02    Dua\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['02']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eb2a6b",
   "metadata": {},
   "source": [
    "> Also note that non-unique indices are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac70c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "828c577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['Ehtisham', 'Ali', 'Ayesha', 'Dua']\n",
    "indices = [2.1, 2.2, 2.3, 2.4,]   \n",
    "\n",
    "s = pd.Series(data=list1, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b772d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1    Ehtisham\n",
      "2.2         Ali\n",
      "2.3      Ayesha\n",
      "2.4         Dua\n",
      "dtype: object\n",
      "\n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(s)\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092569bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "994e36fa",
   "metadata": {},
   "source": [
    "**You can create a series with NaN values, using `np.nan`, which is IEEE 754 floating-point representation of Not a Number. NaN values can act as a placeholder for any missing numerical values in the array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2df858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "262257df",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1, 2.7, np.nan, 54]\n",
    "\n",
    "\n",
    "s = pd.Series(data=list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dd089ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1.0\n",
      "1     2.7\n",
      "2     NaN\n",
      "3    54.0\n",
      "dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(s)\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd141c94",
   "metadata": {},
   "source": [
    "> Also note the `dtype` of the series object is inferred from the data as `float64`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15013374",
   "metadata": {},
   "source": [
    "**You can use the `dtype` argument to specify a datatype to the series object.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5285f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [27, 33, 19]\n",
    "\n",
    "s = pd.Series(data=list1, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bad1e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    27\n",
      "1    33\n",
      "2    19\n",
      "dtype: uint8\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(s)\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd465dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6f4fe88",
   "metadata": {},
   "source": [
    "**Optionally, you can assign a name to a series, which becomes attribute of the series object. Moreover, it becomes the column name, if that series object is used to create a dataframe later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df962ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['Ehtisham', 'Ali', 'Ayesha', 'Dua']\n",
    "\n",
    "indices = ['01', '02', '03', '04']\n",
    "\n",
    "s = pd.Series(data=list1, index=indices, name='myseries1') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9909358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01    Ehtisham\n",
      "02         Ali\n",
      "03      Ayesha\n",
      "04         Dua\n",
      "Name: myseries1, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(s)\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c87fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df897b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cb03fa6",
   "metadata": {},
   "source": [
    "### b. Creating a Series from NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04fabcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(data = np.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898072ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s)\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d980c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "decbafdc",
   "metadata": {},
   "source": [
    "### c. Creating a Series from Python Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b9895dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\n",
    "    'name':\"Ehtisham\", \n",
    "    'gender':\"Male\", \n",
    "    'Role':\"Student\", \n",
    "    'subject':\"Cloud Computing\"\n",
    "}\n",
    "s = pd.Series(data=my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11f3a753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name              Ehtisham\n",
      "gender                Male\n",
      "Role               Student\n",
      "subject    Cloud Computing\n",
      "dtype: object\n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(s)\n",
    "print()\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7591b413",
   "metadata": {},
   "source": [
    "> **When you create a series from dictionary, it will automatically take the keys as index and the value as data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91179a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee73b0eb",
   "metadata": {},
   "source": [
    "### d. Creating a Series from Scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f339f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    25\n",
      "dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(data=25)\n",
    "\n",
    "\n",
    "print(s)\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8ec6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb55f92c",
   "metadata": {},
   "source": [
    "### e. Creating an Empty Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00dda843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_125071/321449064.py:2: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  s = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "# Need to pass atleast `dtype` else you get a warning\n",
    "s = pd.Series()\n",
    "\n",
    "print(s)\n",
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1936d196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03566f7a",
   "metadata": {},
   "source": [
    "## Attributes of Pandas  Series\n",
    "\n",
    "- We can access certain properties called attributes of a series by using that property with the series name using dot `.` notation\n",
    "- Mostly attributes of pandas series are similar to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75eec24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ehtisham Sadiq\n",
       "1               NaN\n",
       "2         Ali Sadiq\n",
       "3      Ayesha Sadiq\n",
       "4         Dua Sadiq\n",
       "5     Khubaib Sadiq\n",
       "6       Adeen Sadiq\n",
       "Name: myseries1, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {\n",
    "        0:\"Ehtisham Sadiq\", 1:np.nan, 2:\"Ali Sadiq\", 3:\"Ayesha Sadiq\", \n",
    "        4:\"Dua Sadiq\", 5:\"Khubaib Sadiq\", 6:\"Adeen Sadiq\"\n",
    "    }\n",
    "\n",
    "s = pd.Series(my_dict, name=\"myseries1\")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31e3b192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myseries1'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `name` attribute of a series object return the name of the series object\n",
    "s.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3a70dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4, 5, 6], dtype='int64')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `index` attribute of a series object return the list of indices and its datatype\n",
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16d495d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ehtisham Sadiq', nan, 'Ali Sadiq', 'Ayesha Sadiq', 'Dua Sadiq',\n",
       "       'Khubaib Sadiq', 'Adeen Sadiq'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `values` attribute of a series object return the list of values and its datatype\n",
    "s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "861a0b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `dtype` attribute of a series object return the type of underlying data\n",
    "s.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ac355d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `shape` attribute of a series object return a tuple of shape of underlying data\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb527404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `nbytes` attribute of a series object return the number of bytes of underlying data (object data type take 8 bytes)\n",
    "s.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7540e822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `size` attribute of a series object return number of elements in the underlying data\n",
    "s.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d77545f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `ndim` attribute of a series object return number of dimensions of underlying data\n",
    "s.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afa6f816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `hasnans` attribute of a series object return true if there are NaN values in the data\n",
    "s.hasnans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781cc20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de967aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "513e1e76",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"500\" height=\"500\"  src=\"images/series-anatomy.png\"  >\n",
    "\n",
    "## Understanding Index in a Series\n",
    "- Every series object has an index associated with every item. \n",
    "- The Pandas series object supports both integer-based (default) and label/string-based indexing and provides a host of methods for performing operations involving the index.\n",
    "<br><br>\n",
    "\n",
    "- Index in series object is used for three purposes:\n",
    "    - Identification\n",
    "    - Selection/Filtering/Subsetting\n",
    "    - Alignment <br><br>\n",
    "    \n",
    "- There are three ways to access elements of a series:\n",
    "    - Using `s[]` operator and specifying the index (integer/label)\n",
    "    - Using `s.loc[]` method and specifying the index (integer/label)\n",
    "    - Using `s.iloc[]` method and specify the position (an integer value from 0 to length-1). It also support negative indexing, the last element can be accessed by an index of -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c13589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "644b79a2",
   "metadata": {},
   "source": [
    "### Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6546df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here write your code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f71a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106d8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89f7942c",
   "metadata": {},
   "source": [
    "## Arithmetic Operations on Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52697924",
   "metadata": {},
   "source": [
    "**Example 1:** Adding two series object with same integer indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "791bf827",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1,3,5,7,9] \n",
    "list2 = [2,4,6,8,10]\n",
    "\n",
    "s1 = pd.Series(data=list1)\n",
    "s2 = pd.Series(data=list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77f81c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    3\n",
      "2    5\n",
      "3    7\n",
      "4    9\n",
      "dtype: int64\n",
      "RangeIndex(start=0, stop=5, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(s1)\n",
    "print(s1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a280ea3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2\n",
      "1     4\n",
      "2     6\n",
      "3     8\n",
      "4    10\n",
      "dtype: int64\n",
      "RangeIndex(start=0, stop=5, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(s2)\n",
    "print(s2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "978891f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3\n",
      "1     7\n",
      "2    11\n",
      "3    15\n",
      "4    19\n",
      "dtype: int64\n",
      "RangeIndex(start=0, stop=5, step=1)\n"
     ]
    }
   ],
   "source": [
    "s3 = s1 + s2\n",
    "\n",
    "print(s3)\n",
    "print(s3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda19315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb0dbca3",
   "metadata": {},
   "source": [
    "**Example 2:** Adding two series object having different integer indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8293cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Series\n",
    "list1 = [6,9,7,5]\n",
    "index1 = [0,1,2,3]\n",
    "s1 = pd.Series(data=list1, index=index1);\n",
    "\n",
    "# Second Series\n",
    "list2 = [8,6,2,1]\n",
    "index2 = [0,2,3,5]\n",
    "s2 = pd.Series(data=list2, index=index2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89a4653a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6\n",
      "1    9\n",
      "2    7\n",
      "3    5\n",
      "dtype: int64\n",
      "Int64Index([0, 1, 2, 3], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(s1)\n",
    "print(s1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aca367d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    8\n",
      "2    6\n",
      "3    2\n",
      "5    1\n",
      "dtype: int64\n",
      "Int64Index([0, 2, 3, 5], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(s2)\n",
    "print(s2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb9341bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    14.0\n",
      "1     NaN\n",
      "2    13.0\n",
      "3     7.0\n",
      "5     NaN\n",
      "dtype: float64\n",
      "Int64Index([0, 1, 2, 3, 5], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "s3 = s1 + s2\n",
    "print(s3)\n",
    "print(s3.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a761b8",
   "metadata": {},
   "source": [
    "**Problem:** While performing mathematical operations on series having mismatched indices, all missing values are filled in with NaN by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f9bdb",
   "metadata": {},
   "source": [
    "**Solution:** To handle this problem, instead of using the operators (`+, -, *, /`), an explicit call to `s.add()`, `s.sub()`, `s.mul()` and `s.div()` is preferred. This allows us to replace the missing values in any of the series witth a specific value, so as to have a concrete output in place of NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7999776a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14.0\n",
       "1     9.0\n",
       "2    13.0\n",
       "3     7.0\n",
       "5     1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.add(s2, fill_value=0) # Compare it with above result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b7e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc8c1503",
   "metadata": {},
   "source": [
    "**My dear fellows, please make time to practice following topics related to Series:**\n",
    "\n",
    "- Boolean/Fancy Indexing and Slicing\n",
    "- Use of `reset_index()` method for completely resetting the index\n",
    "- Use of other manipulation methods like \n",
    "    - `s.pop(index)` is passed an index and it returns the data item at the index and removes it from series\n",
    "    - `s.drop(indexes)` is passed one or a list of indices and returns a series of the data items. Series remains unchanged unless the inplace = True argument is passed\n",
    "    - `s1.append(s2, ignore_index=False, verify_integrity=False)` is used to concatenate two series and return the concatenated series, original series remain unchanged\n",
    "    - `s1.update(s2)` is used to miduft the series `s1` inplace using the values from passed series\n",
    "\n",
    "> **We will discuss these while studying Pandas Dataframe object In Shaa Allah**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f5358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3993db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7d8347d",
   "metadata": {},
   "source": [
    "### Pandas Series vs NumPy 1-D Arrays\n",
    "\n",
    ">- In a series object we can define our own labeled index to access elements of an array. These can be numbers or strings. NumPy arrays are accessed  by their integer position using numbers only.\n",
    ">- In a series object the elements can be indexed in descending order also. In NumPy arrays, the indexing starts with zero for the first element and the index is fixed.\n",
    ">- While performing arithmetic operations on series having misaligned indices, NaN or missing values may be generated. In NumPy arrays, the concept of broadcasting exist and there is no concept of NaN values. While performing arithmetic on incompatible numPy arrays the operation fails.\n",
    ">- Series require more memory. NumPy arrays occupies lesser memory.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8417c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6fd160b",
   "metadata": {},
   "source": [
    "## Practice Questions:\n",
    "- Write a Pandas program to convert a Panda module Series to Python list and it’s type.\n",
    "- Write a Pandas program to add, subtract, multiple and divide two Pandas Series having same indices.\n",
    "- Write a Pandas program to compare the elements of the two Pandas Series.(Hint : pd.eq / pd.equals)\n",
    "- Write a Pandas program to change the data type of given a column or a Series.\n",
    "- Write a Pandas program to convert a given Series to an array(Hint : series.values.tolist())\n",
    "- Write a Pandas program to sort a given Series.\n",
    "- Write a Pandas program to add some data to an existing Series.(Hint : series.append()) \n",
    "- Write a Pandas program to create the mean and standard deviation of the data of a given Series.\n",
    "- Write a Pandas program to get the items of a given series not present in another given series.(series.isin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2261edc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3b3bd0f",
   "metadata": {},
   "source": [
    "\n",
    "<img align=\"right\" width=\"500\" height=\"500\"  src=\"images/dataframe.webp\">\n",
    "\n",
    "\n",
    "## 1. Creating a Dataframe\n",
    "<br><br>\n",
    ">**A Pandas Dataframe is a two-dimensional labeled data structure (like SQL table) with heterogeneously typed columns, having both a row and a column index.**\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "**```pd.DataFrame(data=None, index=None, columns=None, dtype=None)```**\n",
    "- Where,\n",
    "   - `data`: It can be a 2-D NumPy Array, a Dictionary of Python Lists, or a Dictionary of Panda Series (You can also create a dataframe from a file in CSV, Excel, JSON, HTML format or may be from a database table as well).\n",
    "   - `index`: These are the row indices. Will default to RangeIndex (0, 1, 2, ..., n), if index argument is not passed and no indexing information is part of input data.\n",
    "   - `columns`: These are the column indices or labels. Will default to RangeIndex (0, 1, 2, ..., n), if index argument is not passed and no indexing information is part of input data.\n",
    "   - `dtype`: Data type to force. Only a single dtype is allowed. If None, infer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1bde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08420af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7cdb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a70e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d15c7058",
   "metadata": {},
   "source": [
    "#### Creating multiple series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Ehtisham', 'Ali', 'Ayesha', 'Dua']\n",
    "marks = [91.5,93,80,65]\n",
    "age = [21,18,16,6]\n",
    "\n",
    "#Creating a Series by passing list variable to Series() function of pandas \n",
    "name_ser = pd.Series(name)\n",
    "marks_ser = pd.Series(marks)\n",
    "age_ser = pd.Series(age)\n",
    "\n",
    "#Printing Series\n",
    "print(\"Name Series : \", name_ser, sep=\"\\n\")\n",
    "print(\"Marks Series : \", marks_ser, sep=\"\\n\")\n",
    "print(\"Age Series : \", age_ser,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6d90e",
   "metadata": {},
   "source": [
    "#### Creating Dataframe from multiple Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Series by passing list variable to Series() function of pandas \n",
    "name_ser = pd.Series(name)\n",
    "marks_ser = pd.Series(marks)\n",
    "age_ser = pd.Series(age)\n",
    "\n",
    "# Creating a Dictionary by passing series as values of dictionary\n",
    "dic = {'Name':name_ser,\n",
    "      'Marks':marks_ser,\n",
    "      'Age':age_ser\n",
    "      }\n",
    "\n",
    "# Create dataframe by passing dictionary to pd.DataFrame function of pandas\n",
    "df = pd.DataFrame(dic)\n",
    "print(\"Printing of DataFrame .... \")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b1c62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02c29ac",
   "metadata": {},
   "source": [
    "#### How to add new column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "address = pd.Series(['Lahore','Okara','Okara','Okara'])\n",
    "##Creating new column in the dataframe by providing s Series created using list\n",
    "df['Address'] = address\n",
    "print(\"Printing of DataFrame .... \")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35192588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f154a69f",
   "metadata": {},
   "source": [
    "## Data Handling with Pandas..\n",
    "\n",
    "- **Data Reading** : Reading from a csv or an excel – Pandas provide two functions – read_csv() and read_excel() to read data from a csv and an excel file respectively. Command can be used as follows.\n",
    "\n",
    "- **Viewing data** – Viewing data from a data frame can be done by three ways\n",
    " >- using the data frame’s name – returns the top and bottom 5 rows in the data frame.\n",
    " >- using dataframe.head() function\n",
    " >- using dataframe.tail() function\n",
    "\n",
    "- **Data Overview** : To see more details on the data frame, the `info()` function can be used. info() gives an idea about what datatype each series in a data frame points to.\n",
    "\n",
    "- The following functions are used to find the unique entries within a series/column in a data frame.\n",
    " >- datafame.unique() – returns the unique values\n",
    " >- dataframe.nunique() – returns the count of unique values\n",
    " >- dataframe.value_counts() – returns the frequency of each of the categories in the column\n",
    "\n",
    "- In our example, the titanic dataset contains a column called `Survived` which tells if the particular passenger survived the tragedy. Since this value could only be either 0 or 1, we can convert the data type from integer to object.\n",
    " >- `dataframe.astype()` is the function which lets us do the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat datasets/titanic3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.listdir('datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304bf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/recent-grads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1d4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55306a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13227ab2",
   "metadata": {},
   "source": [
    "## Practice Questions Part 1: \n",
    "- Step 1. Import the necessary libraries.\n",
    "- Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/u.user)\n",
    "- Step 3. Assign it to a variable called users and use the `user_id` as index\n",
    "- Step 4. See the first 25 entries\n",
    "- Step 5. See the last 10 entries\n",
    "- Step 6. What is the number of observations in the dataset?\n",
    "- Step 7. What is the number of columns in the dataset?\n",
    "- Step 8. Print the name of all the columns.\n",
    "- Step 9. How is the dataset indexed?\n",
    "- Step 10. What is the data type of each column?\n",
    "- Step 11. Print only the occupation column\n",
    "- Step 12. How many different occupations are in this dataset?\n",
    "- Step 13. What is the most frequent occupation?\n",
    "- Step 14. Summarize the DataFrame.\n",
    "- Step 15. Summarize all the columns\n",
    "- Step 16. Summarize only the occupation column\n",
    "- Step 17. What is the mean age of users?\n",
    "- Step 18. What is the age with least occurrence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data reading\n",
    "url = \"https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/u.user\"\n",
    "users = pd.read_csv(url, delimiter=\"|\")\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7377b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 03\n",
    "# First Method\n",
    "users = pd.read_csv(url, delimiter=\"|\", index_col='user_id')\n",
    "users.head()\n",
    "\n",
    "\n",
    "# Second method\n",
    "# users.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 04\n",
    "users.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964824a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 05\n",
    "users.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041382f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 06\n",
    "users.shape\n",
    "# or \n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62914be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 07 & 08\n",
    "print(\"users.shape : \",users.shape)\n",
    "users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 09\n",
    "users.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ff59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b04b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 10\n",
    "users.dtypes\n",
    " \n",
    "#     or \n",
    "# users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 11\n",
    "users['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f0a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 12\n",
    "# First method\n",
    "users['occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second method\n",
    "users['occupation'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third method\n",
    "users['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98e393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 13\n",
    "users['occupation'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 14\n",
    "users.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 15\n",
    "users.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 16\n",
    "users['occupation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f38ff9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfbf5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 17\n",
    "users['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c9ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task no 18\n",
    "users['age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ab535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.Series([])\n",
    "# pd.DataFrame(dict)\n",
    "# shape\n",
    "# info() -> indcies of columns, columns name, total null values, datatype of each column, range of indcies\n",
    "# dtypes -> return datatype of all columns\n",
    "# describe() -> descriptive view dataset/dataframe (mean, max, min, std, count)\n",
    "# head() -> top records/rows/indcies\n",
    "# tail() -> last 5 records\n",
    "# unique()  -> all unique values in given column(it is invalid for continous data)\n",
    "# nunique() -> return count of unique values\n",
    "# value_counts() -> return unique values along with their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92facbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a91c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aae2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4225b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "498ee523",
   "metadata": {},
   "source": [
    "## Practice Questions Part 2:\n",
    "- Step 1. Import the necessary libraries\n",
    "- Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/Euro_2012_stats_TEAM.csv)\n",
    "- Step 3. Assign it to a variable called `euro12`.\n",
    "- Step 4. Select only the Goal column.\n",
    "- Step 5. How many team participated in the Euro2012?(value_counts/shape)\n",
    "- Step 6. What is the number of columns in the dataset?(shape/info)\n",
    "- Step 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n",
    "- Step 8. Sort the teams by Red Cards, then to Yellow Cards(Hint: sort_values)\n",
    "- Step 9. Calculate the mean Yellow Cards given per Team(Hint: round())\n",
    "- Step 10. Filter teams that scored more than 6 goals\n",
    "- Step 11. Select the teams that start with G(Hint : str.startswith('G'))\n",
    "- Step 12. Select the first 7 columns and all the rows(Hint: iloc())\n",
    "- Step 13. Select all columns except the last 3.(Hint: iloc())\n",
    "- Step 14. Presents/shows only the Shooting Accuracy from England, Italy and Russia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/Euro_2012_stats_TEAM.csv\"\n",
    "euro12 = pd.read_csv(url)\n",
    "euro12.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12['Goals']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12['Team'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c029874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# euro12.shape\n",
    "# or \n",
    "euro12.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "discipline = euro12[['Team','Yellow Cards','Red Cards']]\n",
    "discipline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discipline = discipline.sort_values('Red Cards')\n",
    "# discipline = discipline.sort_values('Yellow Cards')\n",
    "\n",
    "\n",
    "#  Or\n",
    "\n",
    "discipline.sort_values(by =['Red Cards','Yellow Cards'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(discipline.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4525432",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12['Goals']>6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ffefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12[euro12['Goals'] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd564ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12['Team'].str.startswith('G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0377bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12[euro12['Team'].str.startswith('G')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1309ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12.iloc[:,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8df27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12.iloc[:,-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8e7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a65628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # euro12.loc[), ['Team','Shooting Accuracy']]\n",
    "euro12.loc[euro12.Team.isin(['England', 'Italy', 'Russia']), ['Team','Shooting Accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b3bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bad24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5d730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e62cb2f",
   "metadata": {},
   "source": [
    "## All statistical functions\n",
    "- `count()` : Returns the number of times an element/data has occurred (non-null)\n",
    "- `sum()`\t: Returns sum of all values\n",
    "- `mean()` : Returns the average of all values\n",
    "- `median()` : Returns the median of all values\n",
    "- `mode()` : Returns the mode\n",
    "- `std()`\t: Returns the standard deviation\n",
    "- `min()`\t: Returns the minimum of all values\n",
    "- `max()`\t: Returns the maximum of all values\n",
    "- `abs()`\t: Returns the absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f7e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of elements in each column of dataframe \")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b93034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4530e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def3c276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e84798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cdd9edb",
   "metadata": {},
   "source": [
    "## Input and Output\n",
    "\n",
    "- Often, you won’t be creating data but will be having it in some form, and you would want to import it to run your analysis on it. Fortunately, Pandas allows you to do this. Not only does it help in importing data, but you can also save your data in your desired format using Pandas.\n",
    "- The below table shows the formats supported by Pandas, the function to read files using Pandas, and the function to write files.\n",
    "|Input |type      |\tReader\tWriter |\n",
    "|------|----------|----------------|\n",
    "|CSV   |read_csv  |  to_csv        |\n",
    "|JSON  |read_json | to_json\n",
    "|HTML  |read_html |to_html\n",
    "|Excel |read_excel|to_excel\n",
    "|SAS   |read_sas  |–\n",
    "|Python|Pickle    |\tread_pickle\tto_pickle\n",
    "|SQL   |read_sql  |to_sql\n",
    "|Google|Big Query | read_gbq\tto_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236bf81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read input file\n",
    "df = pd.read_csv('datasets/psl.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a2b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da389b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a dataframe to CSV File\n",
    "data = {'Name':['Captain America', 'Iron Man', 'Hulk', 'Thor','Black Panther'],\n",
    "        'Rating':[100, 80, 84, 93, 90],\n",
    "        'Place':['USA','USA','USA','Asgard','Wakanda']}\n",
    "# Create dataframe from above dictionary\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "df.to_csv(\"datasets/avengers1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e93d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat datasets/avengers1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ab45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc0dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39481c21",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "- The aggregation function can be applied against a single or more column. You can either apply the same aggregate function across various columns or different aggregate functions across various columns.\n",
    "- Syntax : \n",
    " >- DataFrame.aggregate(self, func, axis=0, *args, ***kwargs)\n",
    " \n",
    "<img src=\"images/pandas-agg-func.png\" height=400px width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6b77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00061903",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'http://bit.ly/2cLzoxH'\n",
    "# read data from url as pandas dataframe\n",
    "gapminder = pd.read_csv(data_url)\n",
    "gapminder.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_data = gapminder[['continent','pop']]\n",
    "gapminder_data.head()\n",
    "# gapminder.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de645bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Aggregate Functions on Series\n",
    "mean  = gapminder_data['pop'].aggregate('mean')\n",
    "print(\"Mean of population : \", mean)\n",
    "\n",
    "Min  = gapminder_data['pop'].aggregate('min')\n",
    "print(\"Minimum value of population : \", Min)\n",
    "\n",
    "Max  = gapminder_data['pop'].aggregate('max')\n",
    "print(\"Maximum value of population : \", Max)\n",
    "\n",
    "Std  = gapminder_data['pop'].aggregate('std')\n",
    "print(\"Std of population : \", Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ac5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7bec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb466959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using multiple Aggregate Functions on Dataframe\n",
    "gapminder_data['pop'].aggregate(['sum','min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc654c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using multiple Aggregate Functions on Multiple columns of Dataframe\n",
    "gapminder[['pop','lifeExp']].aggregate(['sum','min','max','std','mean','var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also perform above task by using below code\n",
    "gapminder.aggregate({'pop':['sum','min','max'],\n",
    "                    'lifeExp':['sum','min','max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8818b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()  gives overall descriptive view of our dataset\n",
    "gapminder.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43ffbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08379b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "701dc508",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "- Pandas groupby function is used to split the DataFrame into groups based on some criteria. \n",
    "- Similar to the `SQL GROUP BY` clause pandas `DataFrame.groupby()` function is used to collect the identical data into groups and perform aggregate functions on the grouped data. Group by operation involves splitting the data, applying some functions, and finally aggregating the results.\n",
    "\n",
    "<img src=\"images/pandas-groupby-standard-dev.png.webp\" height=500px width=500px>\n",
    "<img src=\"images/groupby-example.png\" height=700px width=700px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc92c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38f42b61",
   "metadata": {},
   "source": [
    "### Syntax of Pandas DataFrame.groupby()\n",
    "\n",
    "       \n",
    "       `DataFrame.groupby(by=None, axis=0, level=None, as_index=True,     \n",
    "       sort=True, group_keys=True, squeeze=<no_default>,      \n",
    "       observed=False, dropna=True)`\n",
    "       \n",
    "       \n",
    "- `by` – List of column names to group by\n",
    "- `axis` – Default to 0. It takes 0 or ‘index’, 1 or ‘columns’\n",
    "- `level` – Used with MultiIndex.\n",
    "- `as_index` – sql style grouped otput.\n",
    "- `sort` – Default to True. Specify whether to sort after group\n",
    "- `group_keys` – add group keys or not\n",
    "- `squeeze` – depricated in new versions\n",
    "- `observed` – This only applies if any of the groupers are Categoricals.\n",
    "- `dropna` – Default to False. Use True to drop None/Nan on sory key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "technologies   = ({\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"Pandas\",\"Hadoop\",\"Spark\",\"Python\",np.nan],\n",
    "    'Fee' :[22000,25000,23000,24000,26000,25000,25000,22000,1500],\n",
    "    'Duration':['30days','50days','55days','40days','60days','35days','30days','50days','40days'],\n",
    "    'Discount':[1000,2300,1000,1200,2500,None,1400,1600,0]\n",
    "          })\n",
    "df = pd.DataFrame(technologies)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a6caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf37f42d",
   "metadata": {},
   "source": [
    "#### Use groupby() to compute the sum of Fee and Discount of each course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Courses']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f22981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2\n",
    "df.groupby(['Courses'])[['Fee','Discount']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly\n",
    "df.groupby(['Courses']).aggregate('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e7e045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa363720",
   "metadata": {},
   "source": [
    "#### pandas groupby() on Two or More Columns like Courses and Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e69a05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Courses','Duration']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b7b54",
   "metadata": {},
   "source": [
    "#### Add Index to the grouped data\n",
    "- By default `groupby()` result doesn’t include row Index, you can add the index using `DataFrame.reset_index()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ff9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Courses','Duration']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be5e6c",
   "metadata": {},
   "source": [
    "#### Remove sorting on grouped results by using `sort` parameter of df.groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ff937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2=df.groupby(by=['Courses'], sort=False).sum()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb7b15e",
   "metadata": {},
   "source": [
    "#### Apply More Aggregations\n",
    "- You can also compute several aggregations at the same time in pandas by passing the list of agg functions to the `aggregate().`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d24cf15",
   "metadata": {},
   "source": [
    "#### Compute minimu and maximum fee of each course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a67d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Courses')['Fee'].aggregate(['min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f17ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby multiple columns & multiple aggregations\n",
    "df.groupby('Courses').aggregate({'Duration':'count',\n",
    "                                'Fee':['min','max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778abea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7e4e53",
   "metadata": {},
   "source": [
    "## Practice Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198aa13",
   "metadata": {},
   "source": [
    "### Regiment\n",
    "- A regiment is a military unit. Its role and size varies markedly, depending on the country, service and/or a specialisation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826893b",
   "metadata": {},
   "source": [
    "#### Step 1. Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9821aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c02ba",
   "metadata": {},
   "source": [
    "#### Step 2. Create the DataFrame with the following values and Assign it to a variable called regiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28246a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n",
    "        'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n",
    "        'name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze', 'Jacon', 'Ryaner', 'Sone', 'Sloan', 'Piger', 'Riani', 'Ali'], \n",
    "        'preTestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n",
    "        'postTestScore': [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]}\n",
    "regiment = pd.DataFrame(raw_data)\n",
    "regiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635b963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c97a2a02",
   "metadata": {},
   "source": [
    "#### Step 3. What is the mean `preTestScore` from the regiment `Nighthawks`(Nightbird/Night owl)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c33f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Method\n",
    "regiment[regiment['regiment'] == 'Nighthawks'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fac618",
   "metadata": {},
   "outputs": [],
   "source": [
    "regiment[regiment['regiment'] == 'Nighthawks']['preTestScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Method\n",
    "regiment[regiment['regiment'] == 'Nighthawks']['preTestScore'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regiment[regiment['regiment'] == 'Nighthawks']\n",
    "\n",
    "# 3rd Method\n",
    "regiment.groupby('regiment').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6611f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "regiment.groupby('regiment').get_group('Nighthawks')['preTestScore'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71420455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d1d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9ef1ea2",
   "metadata": {},
   "source": [
    "#### Step 4. Present/show general statistics by `company` of regiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regiment.groupby('company').describe()\n",
    "\n",
    "regiment.groupby('company').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7103f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5df0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "489c67d0",
   "metadata": {},
   "source": [
    "#### Step 5. What is the mean of each company's preTestScore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "regiment.groupby('company')['preTestScore'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regiment.groupby('company')['preTestScore'].mean()\n",
    "\n",
    "# OR\n",
    "\n",
    "regiment.groupby('company').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf158fa",
   "metadata": {},
   "source": [
    "#### Step 6. Presents/shows the `mean` preTestScores grouped by regiment and company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0473b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "regiment.groupby(['regiment','company'])['preTestScore'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f3cf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# regiment.groupby(['regiment','company'])['preTestScore'].mean()\n",
    "# OR\n",
    "regiment.groupby(['regiment', 'company']).preTestScore.mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1f5ef",
   "metadata": {},
   "source": [
    "#### Step 7. Presents/shows the `mean` preTestScores grouped by regiment and company with reset_index parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c9263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regiment.groupby(['regiment', 'company'])['preTestScore'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20273f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da845e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6aa8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48911819",
   "metadata": {},
   "source": [
    "#### Step 8. Group the entire dataframe by regiment and company , also perform `sum` aggregate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b04db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regiment.groupby(['regiment','company']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5660c165",
   "metadata": {},
   "source": [
    "#### Step 9. What is the number of observations in each regiment and company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "regiment.groupby(['regiment','company']).size()\n",
    "# OR \n",
    "regiment.groupby(['regiment','company']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462657d0",
   "metadata": {},
   "source": [
    "#### Step 10. Iterate over a group and print the name and the whole data from the regiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, data in regiment.groupby('regiment'):\n",
    "    print(\"Group Name :\", name)\n",
    "    print(\"Group Data : \", data,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group the dataframe by regiment, and for each regiment,\n",
    "# for name, group in regiment.groupby('regiment'):\n",
    "#     # print the name of the regiment\n",
    "#     print('Name : ',name)\n",
    "# #     print data of that regiment\n",
    "#     print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c97960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94c74048",
   "metadata": {},
   "source": [
    "## Merging, Joining and Concatenation\n",
    "Before I start with Pandas join and merge functions, let me introduce you to four different types of joins, they are inner join, left join, right join, outer join.\n",
    "<img src=\"images/Untitled.png\" height=500px width=500px align=\"right\"> \n",
    "\n",
    "- **Full outer join**: Combines results from both DataFrames. The result will have all columns from both DataFrames.\n",
    "- **Inner join**: Only those rows which are present in both DataFrame A and DataFrame B will be present in the output.\n",
    "- **Right join**: Right join uses all records from DataFrame B and matching records from DataFrame A.\n",
    "- **Left join**: Left join uses all records from DataFrame A and matching records from DataFrame B.\n",
    "\n",
    "<img src=\"images/joins.png\" height=600px width=600px align=\"left\" > \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ab9cb91",
   "metadata": {},
   "source": [
    "### Merging\n",
    "- Merging a Dataframe with one unique key.\n",
    "\n",
    "#### Syntax:\n",
    "```\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "left_index=False, right_index=False, sort=True)\n",
    "``` \n",
    "- `left` − A DataFrame object.\n",
    "- `right` − Another DataFrame object.\n",
    "- `on` − Columns (names) to join on. Must be found in both the left and right DataFrame objects.\n",
    "- `left_on` − Columns from the left DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame.\n",
    "- `right_on` − Columns from the right DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame.\n",
    "- `left_index` − If True, use the index (row labels) from the left DataFrame as its join key(s). In case of a DataFrame with a MultiIndex (hierarchical), the number of levels must match the number of join keys from the right DataFrame.\n",
    "- `right_index` − Same usage as left_index for the right DataFrame.\n",
    "- `how` − One of 'left', 'right', 'outer', 'inner'. Defaults to inner. Each method has been described below.\n",
    "- `sort` − Sort the result DataFrame by the join keys in lexicographical order. Defaults to True, setting to False will improve the performance substantially in many cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing employee data \n",
    "import pandas as pd\n",
    "data1 = {'key':['K0','K1','K2','K3'],\n",
    "         'Name':['Mercy', 'Prince', 'John', 'Cena'],\n",
    "         'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "\n",
    "data2 = {'key':['K0','K1','K2','K3'],\n",
    "         'Address':['Canada', 'UK', 'India', 'USA'], \n",
    "         'Qualification':['Btech', 'B.A', 'MS', 'Phd']} \n",
    "\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df2 = pd.DataFrame(data2) \n",
    "\n",
    "df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging of two dataframes on basis ok `key` \n",
    "final_df = pd.merge(df1, df2, on='key')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdeb316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc3d47dd",
   "metadata": {},
   "source": [
    "#### Merging Dataframe using multiple keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing employee data \n",
    "\n",
    "data1 = {'key':['K0','K1','K2','K3'],\n",
    "         'Name':['Mercy', 'Prince', 'John', 'Cena'],\n",
    "          'Address':['Canada', 'Australia', 'India', 'Japan'],\n",
    "         'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "\n",
    "data2 = {'key':['K0','K1','K2','K3'],\n",
    "         'Address':['Canada', 'UK', 'India', 'USA'], \n",
    "         'Qualification':['Btech', 'B.A', 'MS', 'Phd']} \n",
    "\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df2 = pd.DataFrame(data2) \n",
    "\n",
    "df1.Address, df2.Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ae03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging of two dataframes on basis ok `key` \n",
    "final_df = pd.merge(df1, df2, on=['key','Address'])\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8403ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11c4a4e7",
   "metadata": {},
   "source": [
    "#### Left merge\n",
    "- In pd.merge() I pass the argument `how = left` to perform a left merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da43cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing employee data \n",
    "\n",
    "data1 = {'key':['K0','K1','K2','K3'],\n",
    "         'Name':['Mercy', 'Prince', 'John', 'Cena'],\n",
    "          'Address':['Canada', 'Australia', 'India', 'Japan'],\n",
    "         'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "\n",
    "data2 = {'key':['K0','K1','K2','K3'],\n",
    "         'Address':['Canada', 'UK', 'India', 'USA'], \n",
    "         'Qualification':['Btech', 'B.A', 'MS', 'Phd']} \n",
    "\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df2 = pd.DataFrame(data2) \n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5630fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging of two dataframes on basis ok `key` \n",
    "final_df = pd.merge(df1, df2, on=['key','Address'], how='left')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477530d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9aba6b4",
   "metadata": {},
   "source": [
    "#### Right merge\n",
    "- In pd.merge() I pass the argument `how = right` to perform a left merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db97cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing employee data \n",
    "\n",
    "data1 = {'key':['K0','K1','K2','K3'],\n",
    "         'Name':['Mercy', 'Prince', 'John', 'Cena'],\n",
    "          'Address':['Canada', 'Australia', 'India', 'Japan'],\n",
    "         'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "\n",
    "data2 = {'key':['K0','K1','K2','K3'],\n",
    "         'Address':['Canada', 'UK', 'India', 'USA'], \n",
    "         'Qualification':['Btech', 'B.A', 'MS', 'Phd']} \n",
    "\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df2 = pd.DataFrame(data2) \n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merging of two dataframes on basis ok `key` \n",
    "final_df = pd.merge(df1, df2, on=['key','Address'], how='right')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd03bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17b7a4dc",
   "metadata": {},
   "source": [
    "#### Outer Merge\n",
    "- In pd.merge(), I pass the argument `how = outer` to perform a outer merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing employee data \n",
    "\n",
    "data1 = {'key':['K0','K1','K2','K3'],\n",
    "         'Name':['Mercy', 'Prince', 'John', 'Cena'],\n",
    "          'Address':['Canada', 'Australia', 'India', 'Japan'],\n",
    "         'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "\n",
    "data2 = {'key':['K0','K1','K2','K3'],\n",
    "         'Address':['Canada', 'UK', 'India', 'USA'], \n",
    "         'Qualification':['Btech', 'B.A', 'MS', 'Phd']} \n",
    "\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df2 = pd.DataFrame(data2) \n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658229b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b324a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merging of two dataframes on basis ok `key` \n",
    "final_df = pd.merge(df1, df2, on=['key','Address'], how='outer')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34723f",
   "metadata": {},
   "source": [
    "## Join\n",
    "- Join is used to combine DataFrames having different indcies values.\n",
    "- `I have two different tables in Python but I’m not sure how to join them. What criteria should I consider? What are the different ways I can join these tables?`\n",
    "- Sound familiar? I have come across this question plenty of times on online discussion forums. Working with one table is fairly straightforward but things become challenging when we have data spread across two or more tables.\n",
    "- This is where the concept of Joins comes in. I cannot emphasize the number of times I have used these Joins in Pandas! They’ve come in especially handy during data science hackathons when I needed to quickly join multiple tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c9017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7fa0d44",
   "metadata": {},
   "source": [
    "#### Understanding the Problem Statement\n",
    "\n",
    "- I’m sure you’re quite familiar with e-commerce sites like `Amazon` and `Flipkart` these days. We are bombarded by their advertisements when we’re visiting non-related websites – that’s the power of targeted marketing!\n",
    "- We’ll take a simple problem from a related marketing brand here. We are given two tables – one which contains data about products and the other that has customer-level information.\n",
    "- We will use these tables to understand how the different types of joins work using Pandas.\n",
    "\n",
    "#### Note: \n",
    " >- Our task is to use our joining skills and generate meaningful information from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The product dataframe contains product details like Product_ID, Product_name, Category, Price, and Seller_City. \n",
    "product=pd.DataFrame({\n",
    "    'Product_ID':[101,102,103,104,105,106,107],\n",
    "    'Product_name':['Watch','Bag','Shoes','Smartphone','Books','Oil','Laptop'],\n",
    "    'Category':['Fashion','Fashion','Fashion','Electronics','Study','Grocery','Electronics'],\n",
    "    'Price':[299.0,1350.50,2999.0,14999.0,145.0,110.0,79999.0],\n",
    "    'Seller_City':['Delhi','Mumbai','Chennai','Kolkata','Delhi','Chennai','Bengalore']\n",
    "})\n",
    "\n",
    "# The customer dataframe contains details like id, name, age, Product_ID, Purchased_Product, and City.\n",
    "customer=pd.DataFrame({\n",
    "    'id':[1,2,3,4,5,6,7,8,9],\n",
    "    'name':['Olivia','Aditya','Cory','Isabell','Dominic','Tyler','Samuel','Daniel','Jeremy'],\n",
    "    'age':[20,25,15,10,30,65,35,18,23],\n",
    "    'Product_ID':[101,0,106,0,103,104,0,0,107],\n",
    "    'Purchased_Product':['Watch','NA','Oil','NA','Shoes','Smartphone','NA','NA','Laptop'],\n",
    "    'City':['Mumbai','Delhi','Bangalore','Chennai','Chennai','Delhi','Kolkata','Delhi','Mumbai']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181585b",
   "metadata": {},
   "source": [
    "- Let’s say we want to know about all the products sold online and who purchased them. We can get this easily using an inner join.\n",
    "\n",
    "- The `merge()` function in Pandas is our friend here. By default, the merge function performs an inner join. It takes both the dataframes as arguments and the name of the column on which the join has to be performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db600c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644f7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46dc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(product, customer, on='Product_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df78879",
   "metadata": {},
   "source": [
    "- Here, I have performed inner join on the product and customer dataframes on the `Product_ID` column.\n",
    "- But, what if the column names are different in the two dataframes? Then, we have to explicitly mention both the column names.\n",
    "- `left_on` and `right_on` are two arguments through which we can achieve this. `left_on` is the name of the key in the left dataframe and `right_on` in the right dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(product, customer, left_on='Product_name', right_on='Purchased_Product')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba408d",
   "metadata": {},
   "source": [
    "- Let’s take things up a notice. The leadership team now wants more details about the products sold. They want to know about all the products sold by the seller to the same city i.e., seller and customer both belong to the same city.\n",
    "\n",
    "- In this case, we have to perform an inner join on both Product_ID and Seller_City of product and Product_ID and City columns of the customer dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(product, customer, left_on=['Product_ID', 'Seller_City'], right_on=['Product_ID','City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcfb3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3f077b2",
   "metadata": {},
   "source": [
    "## Concatenation\n",
    "Concatenating of two or more dataframes using `.concat()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First DataFrame : \", df1, sep=\"\\n\")\n",
    "print(\"Second DataFrame : \", df2, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "# concatenation using concate function\n",
    "pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53080e",
   "metadata": {},
   "source": [
    "The resultant DataFrame has a repeated index. If you want the new Dataframe to have its own index, set `ignore_index` to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "# concatenation using concate function\n",
    "pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa980038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f789d00",
   "metadata": {},
   "source": [
    "#### Note: \n",
    " >- The second DataFrame is concatenating below the first one, making the resultant DataFrame have new rows. If you want the second DataFrame to be added as columns, pass the argument axis=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "# concatenation using concate function\n",
    "pd.concat(frames, axis=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68cdc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c623e2",
   "metadata": {},
   "source": [
    "#### Note: \n",
    " >- Here columns of resultant dataframes are repeated to avoid this, we will append() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b67637",
   "metadata": {},
   "source": [
    "### Concatenating using `.append()` function\n",
    "- Append function concatenates along axis = 0 only. It can take multiple objects as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab0f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf409a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6462fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9119ab0b",
   "metadata": {},
   "source": [
    "## Practices \n",
    "- Import pandas library.\n",
    "- Download both datasets for this exercise from here [data1](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/data1.csv) and [data2](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/data2.csv) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a238e939",
   "metadata": {},
   "source": [
    "### Step 1 : Write a program to join the two given dataframes along rows and assign all to variable `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb9ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('datasets/data1.csv')\n",
    "data2 = pd.read_csv('datasets/data2.csv')\n",
    "print(\"First Data : \", data1, sep=\"\\n\")\n",
    "print(\"Second Data : \", data2, sep=\"\\n\")\n",
    "print(\"Joining of two dataframes along rows wise ...\")\n",
    "data = pd.concat([data1, data2],)\n",
    "data\n",
    "\n",
    "# pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad0c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5eed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "890ff8e3",
   "metadata": {},
   "source": [
    "### Step 2 : Write a program to join the two given dataframes along columns and assign all to variable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ab952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = pd.read_csv('datasets/data1.csv')\n",
    "# data2 = pd.read_csv('datasets/data2.csv')\n",
    "# # print(\"First Data : \", data1, sep=\"\\n\")\n",
    "# # print(\"Second Data : \", data2, sep=\"\\n\")\n",
    "# print(\"Joining of two dataframes along rows wise ...\")\n",
    "data = pd.concat([data1, data2],axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463bcd0",
   "metadata": {},
   "source": [
    "### Step 3 : Write a Pandas program to append rows to an existing DataFrame `data1` and display the combined data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb43b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(['S6','Ehtisham Sadiq', 187], index=['student_id', 'name', 'marks'])\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = data1.append(s1, ignore_index=True)\n",
    "print(\"Combined data : \", combined_data, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75560e1e",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "- For `pandas.DataFrame`, both `join` and `merge` operates on columns and rename the common columns using the given suffix. In terms of row-wise alignment, `merge` provides more flexible control.\n",
    "- Different from `join` and `merge`, `concat` can operate on columns or rows, depending on the given axis, and no renaming is performed. In addition, `concat` allows defining hierachy structures by passing in `keys` and `names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8a6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3033a5a8",
   "metadata": {},
   "source": [
    "## How To Perform Data Visualization with Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb06db2b",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "- Data visualization is the most important step in the life cycle of data science, data analytics, or we can say in data engineering. It is more impressive, interesting and understanding when we represent our study or analysis with the help of colours and graphics. Using visualization elements like graphs, charts, maps, etc., it becomes easier for clients to understand the underlying structure, trends, patterns and relationships among variables within the dataset. Simply explaining the data summary and analysis using plain numbers becomes complicated for both, people coming from technical and non-technical backgrounds. Data visualization gives us a clear idea of what the data wants to convey to us. It makes data neutral for us to understand the data insights.\n",
    "- Data visualization involves operating a huge amount of data and converts it into meaningful and knowledgeable visuals using various tools. For visualizing data we need the best software tools to handle various types of data in structured or unstructured format from different sources such as files, web API, databases, and many more. We must choose the best visualization tool that fulfils all our requirements. The tool should support interactive plots generation, connectivity to data sources, combining data sources, automatically refresh the data, secured access to data sources, and exporting widgets. All these features allow us to make the best visuals of our data and also save time.\n",
    "#### Advantages of Data Visualization\n",
    "<img src=\"images/70513benefits.jpg\" height=600px width=600px >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54ec3a",
   "metadata": {},
   "source": [
    "### Data Visualization with Pandas:\n",
    "\n",
    "- Pandas library in python is mainly used for data analysis. It is not a data visualization library but, we can create basic plots using Pandas. Pandas is highly useful and practical if we want to create exploratory data analysis plots. We do not need to import other data visualization libraries in addition to Pandas for such tasks.\n",
    "\n",
    "- As Pandas is Python’s popular data analysis library, it provides several different functions to visualizing our data with the help of the .plot() function. There is one more advantage of using Pandas for visualization is we can serialize or create a pipeline of data analysis functions and plotting functions. It simplifies the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba7660",
   "metadata": {},
   "source": [
    "#### Creating of Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504dcfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series(np.arange(1,21))\n",
    "y = x**1.2\n",
    "z = x**1.7\n",
    "w = x**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'col1':x,\n",
    "        'col2':y,\n",
    "        'col3':z,\n",
    "        'col4':w}\n",
    "# dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a152fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#creating a DataFrame\n",
    "df = pd.DataFrame(dict1)\n",
    "# Since this is a randomly generated dataframe the values will differ everytime you run this code for everyone.\n",
    "\n",
    "#displaying the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8eccdc",
   "metadata": {},
   "source": [
    "#### Line plot:\n",
    "- Line plot can be created with DataFrame.plot() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2deb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4827ac78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f4058cc",
   "metadata": {},
   "source": [
    "We have got the well-versed line plot for `df` without specifying any type of features in the `.plot()` function. We can plot graphs between two columns also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26aac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='col1', y='col4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['col3','col4']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also generate subplots for individual columns.\n",
    "df.plot(subplots=True, figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def5d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faf189fb",
   "metadata": {},
   "source": [
    "### Bar plot:\n",
    "- Now, we will create bar plots for the same dataframe. Bar plot can be created with `DataFrame.plot.bar()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a97272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac952420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(stacked=True)\n",
    "# In this bar plot, the bars are stacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.barh(stacked=True)\n",
    "# In this bar plot, the bars are stacked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc32ec",
   "metadata": {},
   "source": [
    "### Histogram Plot:\n",
    "Now, let’s generate a histogram for the `df`. Histogram plot can be created with `DataFrame.plot.hist()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9017ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let’s create a histogram with some other features.\n",
    "df.plot.hist(stacked=True, bins=15)\n",
    "# This is a stacked histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.hist(orientation=\"horizontal\", cumulative=True);\n",
    "# Here, we have added a cumulative frequency in the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s create a histogram for each column individually.\n",
    "df.diff().hist(bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da81a6c3",
   "metadata": {},
   "source": [
    "### Box Plot:\n",
    "Now, we will create box plot. Box plot can be created with `DataFrame.plot.box()` function or `DataFrame.boxplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65979c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Method    \n",
    "df.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Method\n",
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef443b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, generating the box plot in a horizontal form.\n",
    "df.plot.box(vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0738cf1b",
   "metadata": {},
   "source": [
    "### Area plot:\n",
    "Now, we will create a area plot. Area plot can be created with `DataFrame.plot.area()` function. By default, it is stacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2915a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will create unstacked area plot.\n",
    "df.plot.area(stacked=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598cc28",
   "metadata": {},
   "source": [
    "### Scatter plot:\n",
    "Now, let’s generate a scatter plot. A Scatter plot can be created with `DataFrame.plot.scatter()` function. As we know scatter plot takes two-positional required arguments i.e. x and y to plot the graph. So, we will give the values of the  `x-axis` and `y-axis` as the name of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter('col4', 'col3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the scatter plot between col_1 and col_2 of dataframe df. Let’s apply some styles.\n",
    "ax = df.plot.scatter('col1', 'col2', color='r', marker=\"*\", s=100)\n",
    "df.plot.scatter(x='col3',y='col4', color='b', s=100, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e532913",
   "metadata": {},
   "source": [
    "In this plot the data is spread with respect to col_2 and col_4 and the we have added some styles also like color, marker  and size of scatters. Let’s see another style of scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='col2', y='col4', c='col1', s=100)\n",
    "# The c keyword is given as the name of a column to provide colours for each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d80c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9452e6ce",
   "metadata": {},
   "source": [
    "### Pie chart:\n",
    "- A Pie plot can be created with `DataFrame.plot.pie()` function or `Series.plot.pie()`. To generate a pie chart we will create series data as a pie chart is created only for one column. Let’s create a series named pie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie = pd.Series(np.random.randint(10,100,4))\n",
    "pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916650e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie.plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply some styles\n",
    "pie.plot.pie(autopct='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d13f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fda6177",
   "metadata": {},
   "source": [
    "### Pie Chart for DataFrame\n",
    "- A Pie chart can be created for DataFrames  also but it will generate individual pies for each column of DataFrame in the form of subplots. Let’s Create a pie chart for the dataframe also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd656a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(np.random.randint(20,100,(5,3)),columns=['col1','col2','col3'])\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04270a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.plot.pie(subplots=True, figsize=(15,15), autopct='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333389c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3631148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c925141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e230f0a",
   "metadata": {},
   "source": [
    "## Practice Exercise Part 1:\n",
    "#### Visualizing the Titanic Disaster\n",
    "- Step 1. Import the necessary libraries\n",
    "- Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/train.csv)\n",
    "- Step 3. Assign it to a variable titanic\n",
    "- Step 4. Set PassengerId as the index\n",
    "- Step 5. Create a pie chart presenting the male/female proportion\n",
    "- Step 6. Create a scatterplot with the Fare payed and the Age, differ the plot color by gender\n",
    "- Step 7. How many people survived and died , display using pie chart?\n",
    "- Step 8. Create a histogram with the Fare payed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315342a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/train.csv\"\n",
    "# titanic = pd.read_csv(url,)\n",
    "\n",
    "# # titanic = pd.read_csv(url,index_col='PassengerId')\n",
    "# # titanic.head()\n",
    "# # OR\n",
    "# titanic.set_index('PassengerId').head()\n",
    "# titanic.shape\n",
    "# males = (titanic.Sex == 'male').sum()\n",
    "# females = (titanic.Sex =='female').sum()\n",
    "# print(\"Total Males : \", males)\n",
    "# print(\"Total Females : \", females)\n",
    "# new_titanic = pd.Series([males,females])\n",
    "# new_titanic\n",
    "# new_titanic.plot.pie(labels=['Male','Female'], autopct='%.2f')\n",
    "# titanic.columns\n",
    "# # titanic.head()\n",
    "# list1 = []\n",
    "# for i in titanic.Sex:\n",
    "#     if i=='male':\n",
    "#         list1.append(1)\n",
    "#     else:\n",
    "#         list1.append(0)\n",
    "# titanic['new_Sex'] = list1\n",
    "# titanic.head()\n",
    "# titanic.plot.scatter(x='Fare',y='Age',c='new_Sex',s=10)\n",
    "# titanic.Fare.min(), titanic.Fare.max(), titanic.Fare.mean()\n",
    "# titanic.Fare.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93668be6",
   "metadata": {},
   "source": [
    "### Practice Exercise Part 2:\n",
    "- Step 1. Import the necessary libraries\n",
    "- Step 2. Import the dataset given below\n",
    "- Step 3. Assign it to a variable `df3`\n",
    "- Step 4. Create a scatter plot of `b` vs `a` by using `red` color.\n",
    "- Step 5. Create a histogram of the `a` column.\n",
    "- Step 6. Create a histogram of the `b` column and use bins=30.\n",
    "- Step 7. Create a boxplot comparing the `a` and `b` columns.\n",
    "- Step 8. Create a kde plot of the `d` column.\n",
    "- Step 9. Create a kde plot of the `d` column and Figure out how to increase the linewidth and make the linestyle dashed. (Note: You would usually not dash a kde plot line)\n",
    "- Step 10. Create an area plot of all the columns for just the rows up to 30. (hint: alpha=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8ced04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = pd.DataFrame(np.random.rand(500,4), columns=['a','b','c','d'])\n",
    "# df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea5673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62784ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28de8d05",
   "metadata": {},
   "source": [
    "## Basic Python Pandas Exercise \n",
    "- In this exercise, we are using `Automobile Dataset` for data analysis. This Dataset has different characteristics of an auto such as body-style, wheel-base, engine-type, price, mileage, horsepower, etc.\n",
    "- Download dataset from this link [Automobile data_set](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/Automobile_data.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url= \"https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/Automobile_data.csv\"\n",
    "automobile = pd.read_csv(url)\n",
    "automobile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a7bf28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abad6b5e",
   "metadata": {},
   "source": [
    "### Exercise 1: From the given dataset print the first and last five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcfe4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d28a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437bfec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03fd1b4e",
   "metadata": {},
   "source": [
    "### Exercise 2: Clean the dataset and update the CSV file(Hint: pd.read_csv(na_values={})\n",
    "Replace all column values which contain `?`, `n.a`, or `NaN.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39057c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile = pd.read_csv(url, na_values={'?':np.nan,\n",
    "                                        'n.a':np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3aeff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f163efa",
   "metadata": {},
   "source": [
    "### Exercise 3: Find the most expensive car company name\n",
    "Print most expensive car’s company name and price.     \n",
    "**Expected Output:**\n",
    "![](images/pandas_printing_most_costly_car_name.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e63d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = automobile.groupby('company')[['price']].max().sort_values(by='price').tail(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce044e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Method\n",
    "a = automobile.groupby(['company'])['price'].max()\n",
    "a.sort_values(ascending=False).reset_index().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6419cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Method\n",
    "b = automobile[['company','price']][automobile['price'] == automobile['price'].max()]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile[['company','price']][automobile.price == automobile.price.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a8637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba999a8",
   "metadata": {},
   "source": [
    "### Exercise 4: Print All Toyota Cars details\n",
    "**Expected Output**\n",
    "![](images/pandas_printing_all_toyota_car_data.png)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automobile[automobile.company == 'toyota']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15550206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First Method\n",
    "# automobile[automobile['company'] == 'toyota']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a631ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Second Method\n",
    "group = automobile.groupby('company')\n",
    "group.get_group('toyota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76d874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5c98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a54f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c14f2da",
   "metadata": {},
   "source": [
    "### Exercise 5: Count total cars per company\n",
    "**Expected Output**\n",
    "![](images/pandas_count_total_cars_per_company.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29634f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile.company.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09ae4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfb28b24",
   "metadata": {},
   "source": [
    "### Exercise 6: Find each company’s Higesht price car\n",
    "**Expected Outcome:**\n",
    "![](images/pandas_printing_each_companys_higesht_price_car.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Method\n",
    "automobile.groupby(['company'])['price'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Method\n",
    "automobile.groupby('company')[['company','price']].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b36d7",
   "metadata": {},
   "source": [
    "### Exercise 7: Find the average mileage of each car making company\n",
    "**Expected Output:**\n",
    "![](images/pandas_printing_average_mileage_of_each_car_making_company.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467aadc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Method\n",
    "automobile.groupby('company')['company','average-mileage'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df38afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Method\n",
    "result = automobile.groupby('company')\n",
    "result['company','average-mileage'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd090654",
   "metadata": {},
   "source": [
    "### Exercise 8: Sort all cars by Price column\n",
    "**Expected Output:**\n",
    "![](images/pandas_sort_all_cars_by_price_column.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile.sort_values(by=['price'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc19be4",
   "metadata": {},
   "source": [
    "### Exercise 9: Concatenate two data frames using the following conditions\n",
    "Create two data frames using the following two dictionaries.\n",
    "![](images/pandas_concatenate_two_data_frames_and_create_key_for_each_data_frame.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280ea9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GermanCars = {'Company': ['Ford', 'Mercedes', 'BMV', 'Audi'], 'Price': [23845, 171995, 135925 , 71400]}\n",
    "japaneseCars = {'Company': ['Toyota', 'Honda', 'Nissan', 'Mitsubishi '], 'Price': [29995, 23600, 61500 , 58900]}\n",
    "German = pd.DataFrame(GermanCars)\n",
    "Japan = pd.DataFrame(japaneseCars)\n",
    "df = pd.concat([German,Japan], keys=['German','Japan'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987546c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea5e8f3f",
   "metadata": {},
   "source": [
    "### Exercise 10: Merge two data frames using the following condition\n",
    "Create two data frames using the following two Dicts, Merge two data frames, and append the second data frame as a new column to the first data frame.\n",
    "![](images/merge_two_data_frames_and_append_new_data_frame_as_new-column.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed369803",
   "metadata": {},
   "outputs": [],
   "source": [
    "Car_Price = {'Company': ['Toyota', 'Honda', 'BMV', 'Audi'], 'Price': [23845, 17995, 135925 , 71400]}\n",
    "car_Horsepower = {'Company': ['Toyota', 'Honda', 'BMV', 'Audi'], 'horsepower': [141, 80, 182 , 160]}\n",
    "price = pd.DataFrame.from_dict(Car_Price)\n",
    "horsepower = pd.DataFrame.from_dict(car_Horsepower)\n",
    "pd.merge(price,horsepower,on='Company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ba3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fd3124d",
   "metadata": {},
   "source": [
    "## Pandas Data Visualization Exercise\n",
    "This is just a quick exercise for you to review the various plots we showed earlier. Use **datasets/practice.csv** to replicate the following plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ab777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb16d8",
   "metadata": {},
   "source": [
    "### Q-01: Import your dataset and also display first five rows of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/practice')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e0fb6",
   "metadata": {},
   "source": [
    "**Q-02: Create this scatter plot of `b` vs `a`. Note the color and size of the points. Also note the figure size. See if you can figure out how to stretch it in a similar fashion. Remeber back to your matplotlib lecture...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e30a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='b',y='a', color='r', s=100, figsize=(10,5), title=\"Scatter plot of b vs a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdee4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56c3f111",
   "metadata": {},
   "source": [
    "**Create a histogram of the 'a' column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe1f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot.hist(by= 'a', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7afe968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a79e90fc",
   "metadata": {},
   "source": [
    "**These plots are okay, but they don't look very polished. Use style sheets to set the style to 'plt.style.use('ggplot') and redo the histogram from above. Also figure out how to add more `bins` and `alpha` to it.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89918ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c04396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e11537c7",
   "metadata": {},
   "source": [
    "**Create a boxplot comparing the `a` and `b` columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f25485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['a','b']].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016065a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3563a20",
   "metadata": {},
   "source": [
    "**Create a kde plot of the `d` column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot('d', kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9157fba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53452bb8",
   "metadata": {},
   "source": [
    "**Figure out how to increase the linewidth and make the linestyle dashed. (Note: You would usually not dash a kde plot line)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1169f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50a7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "195e90c3",
   "metadata": {},
   "source": [
    "**Create an area plot of all the columns for just the rows up to `30.` (hint: use `.ix`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68358a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f5e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2577f2a",
   "metadata": {},
   "source": [
    "# Pandas - Assignment No 01\n",
    "- Click here to solve [Pandas - Assignment no 01](https://www.kaggle.com/code/ehtishamsadiq/pandas-assignment-no-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5084fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f768ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9953560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d092076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f380359b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2c4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef6df26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        body {\n",
       "            background-color: #f2fff2;\n",
       "        }\n",
       "        h1 {\n",
       "            text-align: center;\n",
       "            font-weight: bold;\n",
       "            font-size: 36px;\n",
       "            color: #4295F4;\n",
       "            text-decoration: underline;\n",
       "            padding-top: 15px;\n",
       "        }\n",
       "        \n",
       "        h2 {\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            font-size: 30px;\n",
       "            color: #4A000A;\n",
       "            text-decoration: underline;\n",
       "            padding-top: 10px;\n",
       "        }\n",
       "        \n",
       "        h3 {\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            font-size: 30px;\n",
       "            color: #f0081e;\n",
       "            text-decoration: underline;\n",
       "            padding-top: 5px;\n",
       "        }\n",
       "\n",
       "        \n",
       "        p {\n",
       "            text-align: center;\n",
       "            font-size: 12 px;\n",
       "            color: #0B9923;\n",
       "        }\n",
       "    </style>\n",
       "\n",
       "<h1>Hello</h1>\n",
       "<p>Hello World</p>\n",
       "<h2> Hello</h2>\n",
       "<h3> World </h3>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "style = \"\"\"\n",
    "    <style>\n",
    "        body {\n",
    "            background-color: #f2fff2;\n",
    "        }\n",
    "        h1 {\n",
    "            text-align: center;\n",
    "            font-weight: bold;\n",
    "            font-size: 36px;\n",
    "            color: #4295F4;\n",
    "            text-decoration: underline;\n",
    "            padding-top: 15px;\n",
    "        }\n",
    "        \n",
    "        h2 {\n",
    "            text-align: left;\n",
    "            font-weight: bold;\n",
    "            font-size: 30px;\n",
    "            color: #4A000A;\n",
    "            text-decoration: underline;\n",
    "            padding-top: 10px;\n",
    "        }\n",
    "        \n",
    "        h3 {\n",
    "            text-align: left;\n",
    "            font-weight: bold;\n",
    "            font-size: 30px;\n",
    "            color: #f0081e;\n",
    "            text-decoration: underline;\n",
    "            padding-top: 5px;\n",
    "        }\n",
    "\n",
    "        \n",
    "        p {\n",
    "            text-align: center;\n",
    "            font-size: 12 px;\n",
    "            color: #0B9923;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\"\n",
    "\n",
    "html_content = \"\"\"\n",
    "<h1>Hello</h1>\n",
    "<p>Hello World</p>\n",
    "<h2> Hello</h2>\n",
    "<h3> World </h3>\n",
    "\"\"\"\n",
    "\n",
    "HTML(style + html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c8316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
