{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6686c3f",
   "metadata": {},
   "source": [
    "<img src=\"images/pandas-intro.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc3b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16a38f6b",
   "metadata": {},
   "source": [
    "# Learning Agenda of this Notebook:\n",
    "- What is Pandas and how is it used in AI?\n",
    "- Key features of Pandas\n",
    "- Data Types in Pandas\n",
    "- What does Pandas deal with?\n",
    "\n",
    "- Creating Series in Pandas\n",
    "    - From Python List\n",
    "    - From NumPy Arrays\n",
    "    - From Python Dictionary\n",
    "    - From a scalar value\n",
    "    - Creating empty series object\n",
    "- Attributes of a Pandas Series\n",
    "- Arithmetic Operations on Series\n",
    "\n",
    "- Dataframes in Pandas\n",
    "    - Anatomy of a Dataframe\n",
    "    - Creating Dataframe\n",
    "        - An empty dataframe\n",
    "        - Two-Dimensional NumPy Array\n",
    "        - Dictionary of Python Lists\n",
    "        - Dictionary of Panda Series\n",
    "    - Attributes of a Dataframe\n",
    "    - Bonus\n",
    "- Handling different formats of Data Files\n",
    "- Data Handling with Pandas\n",
    "  - Practice Exercise I\n",
    "  - Practice Exercise II\n",
    "- All Statistical functions in Pandas\n",
    "- Input/Output Operations\n",
    "- Aggregation & Grouping\n",
    "  - Practice Exercise\n",
    "- Merging, Joining and Concatenation\n",
    "  - Practice Exercise\n",
    "- How To Perform Data Visualization with Pandas\n",
    "- Exercise I\n",
    "- Exercise II\n",
    "- Pandas's Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01c774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d0b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5157b310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5184b585",
   "metadata": {},
   "source": [
    "## _IO with CSV EXCEL and JSON Files_\n",
    "\n",
    "<img align=\"center\" width=\"600\" height=\"150\"  src=\"images/fileformats.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410559b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print() -> output\n",
    "# # input() -> \n",
    "\n",
    "# C/C++\n",
    "# cout -> ouput\n",
    "# cin -> input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c92a2",
   "metadata": {},
   "source": [
    "#### Read Pandas Documentation:\n",
    "- General Info: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html\n",
    "\n",
    "\n",
    "- For `read_csv`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html?highlight=read_csv#pandas.read_csv\n",
    "\n",
    "\n",
    "- For `read_excel`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html?highlight=read_excel#pandas.read_excel\n",
    "\n",
    "\n",
    "- For `read_json`:https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.json.read_json.html?highlight=pandas%20read_json#pandas.io.json.read_json\n",
    "\n",
    "\n",
    "- For `to_csv`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv\n",
    "\n",
    "\n",
    "\n",
    "- For `to_excel`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html?highlight=to_excel#pandas.DataFrame.to_excel\n",
    "\n",
    "\n",
    "- For `to_json`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html?highlight=to_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4452f89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6985438f",
   "metadata": {},
   "source": [
    "[Pandas](https://pandas.pydata.org/) provides helper functions to read data from various file formats like CSV, EXCEL, JSON, HTML, SQL table, and many more.\n",
    "1. Reading data from a CSV/TSV File\n",
    "2. Reading a CSV file from a Remote System\n",
    "3. Writing Contents of Dataframe to a CSV File\n",
    "4. Reading data from an EXCEL File\n",
    "5. Writing Contents of Dataframe to an EXCEL File\n",
    "6. Reading data from a JSON File\n",
    "7. Writing Contents of Dataframe to a JSON File\n",
    "8. Reading and Writing with SQL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44990632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3639ba77",
   "metadata": {},
   "source": [
    "## 1. Reading from CSV/TSV Files\n",
    ">**CSV**: A text file in which the values are separated by a comma or a tab character is called a CSV or a TSV file. Each line of the file is a data record and each record consists of one or more fields, separated by a specific character called separator. A CSV/TSV file is typically used to store tabular data (numbers and text), in which each line will have the same number of fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c5a848",
   "metadata": {},
   "source": [
    "###  Reading a  Simple CSV File\n",
    "The `pd.read_csv()` method is used to read a comma-separated file into a DataFrame.\n",
    "```\n",
    "pd.read_csv(fname, delimiter=None, header='infer', skiprows=None , nrows=None , usecols=None,  footer='',...)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat datasets/tips.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614881c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The `read_csv`, by default assumes that the file contains comma separated values, \n",
    "# and the first row of the file conatins names of columns, which will be taken as column labels\n",
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/tips.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d80ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9be47d71",
   "metadata": {},
   "source": [
    "**The `df.head(N)` method is used to select/display first `N` rows, based on `position`, i.e., the integer value corresponding to the position of the row (from 0 to n-1). The default value of `N` is 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de105ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a2ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab2a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7da3c2d",
   "metadata": {},
   "source": [
    "**The `df.tail(N)` method is used to select/display last `N` rows, based on `position`, i.e., the integer value corresponding to the position of the row (from 0 to n-1). The default value of `N` is 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c370543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24246ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db2d1079",
   "metadata": {},
   "source": [
    "**The `df.sample()` method returns a specified number of random rows. This method returns 1 row if a number is not specified.The column names will also be returned, in addition to the sample rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f60937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1839be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b96c7ed6",
   "metadata": {},
   "source": [
    "### Reading a CSV File having a Delimiter, other than Comma\n",
    "- By default, the `read_csv()` expect comma as seperator. But if the CSV file has some other seperator or delimiter like (semi-collon or tab), it will raise an error.\n",
    "- To handler the issue we need to pass specific value to the `delimiter` argument of `read_csv()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35192588",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat datasets/datawithdelimiter.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b19201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/datawithdelimiter.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d83767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/datawithdelimiter.csv\", delimiter=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f2130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556cccec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9837718",
   "metadata": {},
   "source": [
    "### Reading a CSV File not having Column Labels\n",
    "- By default the `read_csv()` method assume the first row of the file will contain column labels\n",
    "- If this is not the case, i.e., the file do not contain column labels rather data, it will be dealt as column label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/classmarkswithoutcollabels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8893b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/classmarkswithoutcollabels.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53beb759",
   "metadata": {},
   "source": [
    "**To read such files, you have to pass the parameter `header=None` to the `read_csv()` method as shown below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/classmarkswithoutcollabels.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c73601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1d9333d",
   "metadata": {},
   "source": [
    "**Now if you want to assign new column labels to make them more understandable, you can assign the list of column labels to the `columns` attribute of the dataframe object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c054dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Roll No','Gender','Group', 'Math','Eng','Comp','Bio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257ade9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a60683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66156f64",
   "metadata": {},
   "source": [
    "### Reading a CSV File having Comments in the beginning\n",
    "- You may get an error while reading a CSV file because someone may have added few comments on the top of the file. In pandas we can still read the data set by skipping few rows from the top.\n",
    "- To deal with the ParseError, open the csv file in the text editor and check if you have some comments on the top.\n",
    "- If yes, then count the number of rows to skip.\n",
    "- While reading file, pass the parameter **skiprows = n** (number of rows in the beginninghaving comments to skip)\n",
    "- While reading file, pass the parameter **skipfooter = n** (number of rows at the end having comments to skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try reading a csv file having 3 comments lines in the beginning.\n",
    "!cat datasets/classmarkswithtopcomments.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try reading a csv file having 3 comments lines in the beginning.\n",
    "df = pd.read_csv(\"datasets/classmarkswithtopcomments.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try reading a csv file having 3 comments lines in the beginning.\n",
    "df = pd.read_csv(\"datasets/classmarkswithtopcomments.csv\", skiprows=3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e934a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fb09049",
   "metadata": {},
   "source": [
    "### Reading a portion of CSV File in a Dataframe\n",
    "- Suppose the dataset inside the csv file is too big and you don't want to spend that much time for reading that data\n",
    "- Or might be your system crashes, when you try to load that much data\n",
    "- Solution is read\n",
    "    - Specific number of rows by passing `nrows` parameter to `read_csv()` method\n",
    "    - Specific number of columns by passing `usecols` parameter to `read_csv()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a40c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read just 10 rows from the csv file by passing the number of rows to read to `nrows` argument\n",
    "df = pd.read_csv('datasets/classmarks.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb28946",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('datasets/classmarks.csv', nrows=5, usecols=['rollno','gender','group','age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7d29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809cfc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64c85fd7",
   "metadata": {},
   "source": [
    "##  Reading a CSV File from a Remote System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7878b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED]..... \n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54838d4",
   "metadata": {},
   "source": [
    "### a. Reading a CSV file from GitHub Gist\n",
    "\n",
    "The `churn_dataset.csv` file actually resides on my GitHub Gist at following URL:\n",
    "\n",
    "https://raw.githubusercontent.com/ehtisham-sadiq/NoSQL-with-MongoDB/main/datasets/churn_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/ehtisham-sadiq/NoSQL-with-MongoDB/main/datasets/churn_dataset.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8893ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1675168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d376355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0cdcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48dde46f",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "-  Reading a CSV file from a Google Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f9cc29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb9c7575",
   "metadata": {},
   "source": [
    "##  Writing Contents of Dataframe to a CSV File\n",
    "- The `pd.to_csv()` method is used to write the contents of a dataframe (with indices) to a CSV file.\n",
    "- The only required argument is the file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f848761",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.read_csv('datasets/classmarks.csv')\n",
    "df_class.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92157a09",
   "metadata": {},
   "source": [
    ">- Let us create a new dataframe from above dataframe containing records of only group B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8852c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_class['group'] == 'group B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30601b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_class['group'] == 'group B')\n",
    "mask.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7631931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_groupB = df_class.loc[mask]\n",
    "df_class_groupB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_groupB.to_csv('datasets/classmarksgroupB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed63d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/classmarksgroupB.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f3a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_groupB.to_csv('datasets/classmarksgroupB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/classmarksgroupB.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea97d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75948040",
   "metadata": {},
   "source": [
    "## I/O with EXCEL Files\n",
    ">**XLSX**: XLSX is a Microsoft Excel Open XML file format. It also comes under the Spreadsheet file format. It is an XML-based file format created by Microsoft Excel. In XLSX data is organized under the cells and columns in a sheet. Each XLSX file may contain one or more sheets. So a workbook can contain multiple sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xlrd xlwt openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aec2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(io='datasets/classmarks.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271af130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212dda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c6e1c2d",
   "metadata": {},
   "source": [
    "### Reading Excel Workbook with Multiple Sheets\n",
    "- By default `pd.read_excel()` function read only the first sheet.\n",
    "- What if we want to read an Excel file having multiple sheets.\n",
    "- The `big_mart_sales_with_multiple_sheets.xlsx` is a workbook that contains three sheets for different years data. The sheet names are 1985, 1987, and 1997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af41022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('datasets/big_mart_sales_with_multiple_sheets.xlsx')\n",
    "# if you check/view the data you can see, it only contains the data of first excel sheet (for the year 1985)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7829c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032814f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1985 = pd.read_excel('datasets/big_mart_sales_with_multiple_sheets.xlsx',sheet_name='1985')\n",
    "df_1987 = pd.read_excel('datasets/big_mart_sales_with_multiple_sheets.xlsx',sheet_name='1987')\n",
    "df_1997 = pd.read_excel('datasets/big_mart_sales_with_multiple_sheets.xlsx',sheet_name='1997')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aaa2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1985.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20689f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1987.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68bc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1997.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26efc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8971c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a803c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e2e906",
   "metadata": {},
   "source": [
    "###  Writing Contents of Dataframe to an EXCEL File\n",
    "- The `pd.to_excel()` method is used to write the contents of a dataframe (with indices) to an Excel file.\n",
    "- The only required argument is the file path.\n",
    "\n",
    "\n",
    ">- Let us create a new single dataframe after concatenating all the above three dataframes using `pd.concat()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13053375",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat(objs=[df_1985, df_1987, df_1997])\n",
    "\n",
    "df_concatenated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c557be0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deb9cbf8",
   "metadata": {},
   "source": [
    "**Note the total number of rows in this dataframe equals to `1463+932+930 = 3325`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can store the concatenated data inside your dataframe into a single Excel file\n",
    "# You can mention the argument `index= false` for not storing row indices (0, 1,2,3,... in the Excel file.\n",
    "\n",
    "df_concatenated.to_excel(excel_writer='datasets/temp.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us verify\n",
    "data = pd.read_excel(io='datasets/temp.xlsx')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc28d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fe223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db14a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797e46af",
   "metadata": {},
   "source": [
    "##  I/O with JSON Files\n",
    "\n",
    ">**JSON**: JavaScript Object Notation is a text-based open standard file format that uses human-readable text consisting of attribute–value pairs and arrays. It is a data interchange format that is used to store and transfer the data via Internet, primarily between a web client and a server.\n",
    "\n",
    "#### To view content of any json file , visit this [website](http://jsonviewer.stack.hu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abbedca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install SQLAlchemy psycopg2-binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eda043",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat datasets/simple.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8767e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the json file using read_json method of pandas library\n",
    "df = pd.read_json('datasets/simple.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226699ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5579ce2",
   "metadata": {},
   "source": [
    "###  Reading JSON File having each record in a separate line\n",
    "- Some of the json files are written as records i.e each json line is a separate json object. For example:\n",
    "```\n",
    "{ 'name' : 'Ahsan', 'roll_no' : '100' } # line 1\n",
    "{ 'name' : 'Ayesha' , 'roll_no' : '101' } # line 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/simple_records.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read such file you need to pass `lines=True` to the `read_json()` method of dataframe\n",
    "df = pd.read_json('datasets/simple_records.json', lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81636f",
   "metadata": {},
   "source": [
    "##  Writing Contents of Dataframe to a JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('datasets/temp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62784ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('datasets/temp.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2725e74",
   "metadata": {},
   "source": [
    "##  Reading and writing with SQL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all we install mysql.connector on our machine\n",
    "!pip3 install mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2ab79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, we import mysql.connector to create connection object\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285723e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third we create our connection object\n",
    "conn = mysql.connector.connect(host='localhost',user='root',password='Pucit12345#',database='ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c436ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will execute our query\n",
    "df = pd.read_sql_query(\"SELECT * FROM DataTable\",conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3475f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34a443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2a33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6721a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f0b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c76fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5084fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f768ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9953560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d092076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f380359b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2c4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6df26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "style = \"\"\"\n",
    "    <style>\n",
    "        body {\n",
    "            background-color: #f2fff2;\n",
    "        }\n",
    "        h1 {\n",
    "            text-align: center;\n",
    "            font-weight: bold;\n",
    "            font-size: 36px;\n",
    "            color: #4295F4;\n",
    "            text-decoration: underline;\n",
    "            padding-top: 15px;\n",
    "        }\n",
    "        \n",
    "        h2 {\n",
    "            text-align: left;\n",
    "            font-weight: bold;\n",
    "            font-size: 30px;\n",
    "            color: #4A000A;\n",
    "            text-decoration: underline;\n",
    "            padding-top: 10px;\n",
    "        }\n",
    "        \n",
    "        h3 {\n",
    "            text-align: left;\n",
    "            font-weight: bold;\n",
    "            font-size: 30px;\n",
    "            color: #f0081e;\n",
    "            text-decoration: underline;\n",
    "            padding-top: 5px;\n",
    "        }\n",
    "\n",
    "        \n",
    "        p {\n",
    "            text-align: center;\n",
    "            font-size: 12 px;\n",
    "            color: #0B9923;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\"\n",
    "\n",
    "html_content = \"\"\"\n",
    "<h1>Hello</h1>\n",
    "<p>Hello World</p>\n",
    "<h2> Hello</h2>\n",
    "<h3> World </h3>\n",
    "\"\"\"\n",
    "\n",
    "HTML(style + html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c8316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
