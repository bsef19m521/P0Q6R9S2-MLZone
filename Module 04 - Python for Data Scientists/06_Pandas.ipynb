{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6686c3f",
   "metadata": {},
   "source": [
    "<img src=\"images/pandas-intro.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc3b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16a38f6b",
   "metadata": {},
   "source": [
    "# Learning Agenda of this Notebook:\n",
    "- What is Pandas and how is it used in AI?\n",
    "- Key features of Pandas\n",
    "- Data Types in Pandas\n",
    "- What does Pandas deal with?\n",
    "\n",
    "- Creating Series in Pandas\n",
    "    - From Python List\n",
    "    - From NumPy Arrays\n",
    "    - From Python Dictionary\n",
    "    - From a scalar value\n",
    "    - Creating empty series object\n",
    "- Attributes of a Pandas Series\n",
    "- Arithmetic Operations on Series\n",
    "\n",
    "- Dataframes in Pandas\n",
    "    - Anatomy of a Dataframe\n",
    "    - Creating Dataframe\n",
    "        - An empty dataframe\n",
    "        - Two-Dimensional NumPy Array\n",
    "        - Dictionary of Python Lists\n",
    "        - Dictionary of Panda Series\n",
    "    - Attributes of a Dataframe\n",
    "    - Bonus\n",
    "- Different file formats in Pandas \n",
    "- Indexing, Subsetting and Slicing Dataframes\n",
    "    - Practice Exercise I\n",
    "- Modifying Dataframes\n",
    "- Data Handling with Pandas\n",
    "  - Practice Exercise I\n",
    "  - Practice Exercise II\n",
    "- All Statistical functions in Pandas\n",
    "- Input/Output Operations\n",
    "- Aggregation & Grouping\n",
    "  - Practice Exercise\n",
    "- Merging, Joining and Concatenation\n",
    "  - Practice Exercise\n",
    "- How To Perform Data Visualization with Pandas\n",
    "- Exercise I\n",
    "- Exercise II\n",
    "- Pandas's Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01c774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d0b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5157b310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce7aab1c",
   "metadata": {},
   "source": [
    "## Outline of Notebook\n",
    "\n",
    "1. Identify the Columns having Null/Missing values using `df.isna()` method\n",
    "2. Handle/Impute the Null/Missing Values under the `scholarship` Column using `df.loc[mask,col]=value`\n",
    "3. Handle/Impute the Null/Missing Values under the `group` Column using `df.loc[mask,col]=value`\n",
    "4. Handle Missing values under a Numeric/Categorical Column using `fillna()`\n",
    "5. Handle Repeating Values (for same information) under the `session` Column\n",
    "6. Create a new Column by Modifying an Existing Column\n",
    "7. Delete Rows Having NaN values using `df.dropna()` method\n",
    "8. Convert Categorical Variables into Numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56b9a6",
   "metadata": {},
   "source": [
    "### Important Points:\n",
    "- In Pandas, To impute numerical we use mean or median of column.\n",
    "- In Pandas, To impute categorical we use mode.\n",
    "- In Real world, we use SimpleImputer or KNNImputer for imputation. These both are available in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb32aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/groupdata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fc252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6606727b",
   "metadata": {},
   "source": [
    "- Whenever the **`pd.read_csv()`** method detects a missing value (nothing between two commas in a csv file or an empty cell in Excel) it flags it with NaN. There can be many reasons for these NaN values, one can be that the data is gathered via google form from people and this field might be optional and skipped.\n",
    "- There can also be a scenario that a user has entered some text under a numeric field about which he/she do not have any information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d60724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c21cf2f",
   "metadata": {},
   "source": [
    "## 1. Identify the Columns having Null/Missing values\n",
    "- The **`df.isna()`** method isrecommended to use than `df.isnull()`, which return a boolean same-sized object that indicates whether an element is NA value or not. Missing values get mapped to True. Everything else gets mapped to False values. Remember, characters such as empty strings ``''`` or `numpy.inf` are not considered NA values.\n",
    "- The **`df.notna()`** method is recommended to use than `df.notnull()` methods return a boolean same-sized object that indicates whether an element is NA value or not. Non-missing values get mapped to True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66707779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbff813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use sum() on this dataframe object of Boolean values (True is mapped to 1)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, we can use sum() on this dataframe object of Boolean values (True is is mapped to 1)\n",
    "df.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7958f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccf47a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b5a98e0",
   "metadata": {},
   "source": [
    "## 2. Handle/Impute the Null/Missing Values under the `scholarship` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d005929",
   "metadata": {},
   "source": [
    "#### a. Identify the Rows under the `scholarship` Column having Null/Missing values\n",
    "- The `df.isna()` method works equally good on Series objects as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51aa67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.scholarship.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44990632",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.scholarship.isna()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc404dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return only those rows of dataframe having null values under the scholarship column\n",
    "df[mask]         # df[df.scholarship.isna()] or \n",
    "df.loc[mask, :]  # df.loc[df.scholarship.isna(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dadcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5876faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51a0cab9",
   "metadata": {},
   "source": [
    "#### b. Replace the Null/Missing Values under the `scholarship` Column\n",
    "- After detecting the NaN values, the next question is, what value we should write in the cells where we have Null/Missing values under the `scholarship` column\n",
    "- Suppose, we want to put the average values at the place of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean of the scholarship column\n",
    "df.scholarship.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.scholarship.isna(), 'scholarship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.scholarship.isna(), 'scholarship'] = df.scholarship.mean()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b064523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ef5e547",
   "metadata": {},
   "source": [
    "## 3. Handle/Impute the Null/Missing Values under the `group` Column\n",
    "- The `group` column contains categorical values, i.e., a value that can take on one of a limited, and usually fixed, number of possible values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc796d",
   "metadata": {},
   "source": [
    "#### a. Identify the Rows under the `group` Column having Null/Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ebf670",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.group.isna()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask]          # df[df.group.isna()]\n",
    "df.loc[mask, :]   # df.loc[df.group.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f95f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57950716",
   "metadata": {},
   "source": [
    "#### b. Replace the Null/Missing Values under the `group` Column\n",
    "- After detecting the NaN values, the next question is, what value we should write in the cells where we have Null/Missing values\n",
    "- Since this is a categorical column having datatype object (group A, group B, group C, ...), so let us replace it with th value inside the column having the maximum frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cf156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use value_counts() function which return a Series containing counts of unique values (in descending order)\n",
    "# with the most frequently-occurring element at first. It excludes NA values by default.\n",
    "df.group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.group.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a48f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only those records under group column having Null values\n",
    "mask = df.group.isna()\n",
    "df.loc[mask, 'group']     # df.loc[(df.group.isna()), 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us replace these values with maximum occurring value in the `group` column\n",
    "df.loc[(df.group.isna()),'group'] = df.group.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306ab2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3a43d9c",
   "metadata": {},
   "source": [
    "> Note that in the original dataframe `Yusuf` group information was missing, and now it is `group C` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5080f",
   "metadata": {},
   "source": [
    "## 4. Handle Missing values under a Numeric/Categorical Column using `fillna()`\n",
    "\n",
    "#### a. Replace the Null/Missing Values under the `scholarship` Column using `fillna()`\n",
    "- This is more recommended way of filling in the Null values within columns of your dataset rather than the use of the `loc` method.\n",
    "```\n",
    "object.fillna(value, method, inplace=True)\n",
    "```\n",
    "- The only required argument is either the `value`, with which we want to replace the missing values OR the `method` to be used to replace the missing values\n",
    "- Returns object with missing values filled or None if ``inplace=True``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/groupdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f6d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b36ff",
   "metadata": {},
   "source": [
    ">- Before proceeding, tell me why we use `na_values` argument in `pd.read_csv()` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.scholarship.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = df.scholarship.mean()\n",
    "mean_value\n",
    "median_value  = df.scholarship.median()\n",
    "median_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc622ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time instead of loc, use fillna() method with just two arguments\n",
    "# inplace=True parameter ensure that this happens in the original dataframe\n",
    "\n",
    "df.scholarship.fillna(value=mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edefe8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the result\n",
    "df.loc[df.scholarship.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35192588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83655bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17316e33",
   "metadata": {},
   "source": [
    "#### b. Replace the Null/Missing Values under the `group` Column using `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33639e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40bbb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mode = df.group.mode()[0]\n",
    "group_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9240d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group.fillna(value=group_mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e1d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da347b",
   "metadata": {},
   "source": [
    "> Fill missing values of subj1 and subj2 columns with the mean of the column using `fillna()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503bc2f1",
   "metadata": {},
   "source": [
    "#### c. Replace the Null/Missing Values under the` scholarship` and `group` Column using `ffill` and `bfill` Arguments\n",
    "- In above examples, we have used the mean value in case of numeric column and mode value in case of a categorical column as the filling value to the `fillna()` method\n",
    "```\n",
    "object.fillna(value, method, inplace=True)\n",
    "```\n",
    "\n",
    "- We can pass `ffill` or `bfill` as method argument to the `fillna()` method. This will replace the null values with other values from the DataFrame\n",
    "- `ffill` (Forward fill): It fills the NaN value with the previous value\n",
    "- `bfill` (Back fill): It fills the NaN value with the Next/Upcoming value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b78ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/groupdata.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bebbcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b69381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill or ffill attribute\n",
    "# If have NaN value, just carry forward the previous value\n",
    "# using ffill attribute, you can fill the NaN value with the previous value in that column\n",
    "df.fillna(method = 'ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14314b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you can use bfill method to fill the NaN values with the next value in that column\n",
    "df.fillna(method = 'bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b06d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be448df2",
   "metadata": {},
   "source": [
    "## 5. Handle Repeating Values (for same information) under the `session` Column\n",
    "- If you observe the values under the `session` column, you can observe that it is a categorical column containing four different categories (as values).\n",
    "    - Notice that the categories `MORNING` and `MOR` are same\n",
    "    - Similarly, `AFTERNOON` and `AFT` are same\n",
    "- This happens when you have collected data from different sources, where same information is written in different ways\n",
    "- So the `session` column has four different categories (as values) but should have only two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aae2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/groupdata.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e28835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['session'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc2475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a86463d6",
   "metadata": {},
   "source": [
    "####  Handle  the Repeating Values under the session Column using `map()`\n",
    "- To keep the data clean we will map all these values to only two categories to `MOR` , `AFT`  using the map() function.\n",
    "```\n",
    "df.map(mapping, na_action=None)\n",
    "```\n",
    "- The `map()` method is used for substituting each value in a Series with another value, that may be derived from a `dict`. The `map()` method returns a series after performing the mapping\n",
    "- You can give `ignore` as second argument which will propagate NaN values, without passing them to the mapping correspondence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e197889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do this, let us create a new mapping (dictionary) \n",
    "dict1 = {\n",
    "    'MORNING' : 'MOR',\n",
    "    'MOR' : 'MOR',\n",
    "    'AFTERNOON' : 'AFT',\n",
    "    'AFT': 'AFT',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590fdf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns a series with the same index as caller, the original series remains unchanged. \n",
    "# So we have assigned the resulting series to `df.session` series\n",
    "df.session.map(dict1)  # or df['session'].map(dict1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ba115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.session = df.session.map(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db94e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of new categories in the column session\n",
    "# Observe we have managed to properly manage the values inside the session column\n",
    "df.session.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets verify the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe929f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd1fc9e7",
   "metadata": {},
   "source": [
    "## 6. Create a new Column by Modifying an Existing Column\n",
    "- We have a column scholarship in the dataset, which is in Pak Rupees\n",
    "- Suppose you want to have a new column which should represent the scholarship in `US Dollars`\n",
    "- For that we need to add a new column by dividing each value of scholarship with 285."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e60d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/groupdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cf04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.scholarship.apply(lambda x: x/285)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee4fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Scholarship_in_$'] = df.scholarship.apply(lambda x : x/285)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132acbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb023c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6269f35c",
   "metadata": {},
   "source": [
    "## 7. Delete Rows Having NaN values using `df.dropna()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59599665",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/groupdata.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fdf82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "16*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a914d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bccf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use dropna() method to drop all the rows, it it has any na value\n",
    "df1 = df.dropna()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9851a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Arguments to dropna()\n",
    "df2 = df.dropna(axis=0, how='any')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62835782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we set how='all` it means drop a row only if all of its values are NA\n",
    "df2 = df.dropna(axis=0, how='all')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624739a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of subset argument and pass it a list of columns based on whose values you want to drop a row\n",
    "df2 = df.dropna(axis=0, how='any', subset=['subj1'])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bae9b9",
   "metadata": {},
   "source": [
    "## 8. Convert Categorical Variables into Numerical\n",
    "- Most of the machine learning algorithms do not take categorical variables so we need to convert them into numerical ones. \n",
    "- We can do this using Pandas function `pd.get_dummies()`, which will create a binary column for each of the categories. \n",
    "```\n",
    "pd.get_dummies(data, drop_first=False)\n",
    "```\n",
    "- Where, the only required argument is `data` which can be a dataframe or a series\n",
    "- The parameter drop_first : bool, default False Whether to get k-1 dummies out of k categorical levels by removing the first level.\n",
    "\n",
    "**Note:** Making a dummy variable will take all the `K` distinct values in one coumn and make `K` columns out of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a500a",
   "metadata": {},
   "source": [
    "#### a. Convert all categorical variables into dummy/indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/groupdata.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently we have 10 columns in the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c90a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categorical variables into dummy/indicator variables\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us view the datafreame, keep a note on the number of columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3337d625",
   "metadata": {},
   "source": [
    "- So we have 37 columns\n",
    "- Even though one-hot encoding is a good way to convert your categorical columns to numerical columns\n",
    "- But it adds a lot of dimensionality to your data, i.e., increase the number of columns\n",
    "- It also become difficult to deal with that much number of columns\n",
    "- This is a trade-off, which is handled by technique called dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d842f",
   "metadata": {},
   "source": [
    "#### b. Perform One-Hot Encoding for Categorical Column `gender` Only\n",
    "- In our dataframe, the gender column is a categorical column having two values 'male' and 'female'\n",
    "- It will create a dummy binary columns.  \n",
    "- This is also known as `One Hot Encoding`. You will learn more encoding techniques in the data pre-processing module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/groupdata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c95103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert only gender variable into dummy/indicator variables\n",
    "df2 = pd.get_dummies(df1[['gender']])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ed62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we donot need two separate columns, so simply use the `drop_first` argument of get_dummies to handle this\n",
    "df2 = pd.get_dummies(df1[['gender']], drop_first=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will talk about join in the next session in detail.\n",
    "df3 = df.join(df2['gender_Male'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f425f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302c461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "277f390b",
   "metadata": {},
   "source": [
    "## Practice Questions\n",
    "\n",
    "For the practice questions, we will use following dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dict1 ={\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001],\n",
    "'salesman_id':[5002,5003,5001,np.nan,5002,5001,5001,np.nan,5003,5002,5003,np.nan]\n",
    "}\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a5039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59149d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff25537",
   "metadata": {},
   "source": [
    "#### Write a Pandas program to drop the rows where at least one element is missing in a given DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f1d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4fca4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c1178c4",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "### Create a heatmap for more information about the distribution of missing values in a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe65b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743eeeed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2602de05",
   "metadata": {},
   "source": [
    "## All statistical functions\n",
    "- `count()`: Returns the number of times an element/data has occurred (non-null)\n",
    "- `sum()`: Returns sum of all values\n",
    "- `mean()`: Returns the average of all values\n",
    "- `median()`: Returns the median of all values\n",
    "- `mode()`: Returns the mode\n",
    "- `std()`: Returns the standard deviation\n",
    "- `min()`: Returns the minimum of all values\n",
    "- `max()`: Returns the maximum of all values\n",
    "- `abs()`: Returns the absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "-12.34, abs(-12.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8295ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe method is used to calculate the count, mean, standard deviation, minimum, \n",
    "#maximum and percentile values\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65988ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "498ee523",
   "metadata": {},
   "source": [
    "## Practice Questions Part 2:\n",
    "- Step 1. Import the necessary libraries\n",
    "- Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/ehtisham-sadiq/P0Q6R9S2-MLZone/main/Module%2004%20-%20Python%20for%20Data%20Scientists/datasets/Euro_2012_stats_TEAM.csv)\n",
    "- Step 3. Assign it to a variable called `euro12`.\n",
    "- Step 4. Select only the Goal column.\n",
    "- Step 5. How many team participated in the Euro2012\n",
    "- Step 6. What is the number of columns in the dataset\n",
    "- Step 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n",
    "- Step 8. Sort the teams by Red Cards, then to Yellow Cards\n",
    "- Step 9. Calculate the mean Yellow Cards given per Team\n",
    "- Step 10. Filter teams that scored more than 6 goals\n",
    "- Step 11. Select the teams that start with G\n",
    "- Step 12. Select the first 7 columns and all the rows\n",
    "- Step 13. Select all columns except the last 3\n",
    "- Step 14. Presents/shows only the Shooting Accuracy from England, Italy and Russia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/ehtisham-sadiq/P0Q6R9S2-MLZone/main/Module%2004%20-%20Python%20for%20Data%20Scientists/datasets/Euro_2012_stats_TEAM.csv\"\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e09879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# displayy all the columns and rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881788cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12 = pd.read_csv(url) # Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8816043",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12.head() # View the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12['Goals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many teams played in euro 2012\n",
    "# euro12.shape[0]\n",
    "euro12['Team'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of columns\n",
    "euro12.shape[1] # or  len(euro12.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd03dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the columns to discipline \n",
    "discipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ef27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort discipline in descending order\n",
    "discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean Yellow Cards given per Team\n",
    "discipline['Yellow Cards'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff44f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter teams that scored more than 6 goals\n",
    "euro12['Goals'] > 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12[euro12['Goals'] > 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7217a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the teams that start with G\n",
    "\n",
    "mask = euro12['Team'].str.startswith('G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27fd257",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02459b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 7 columns and all the rows\n",
    "\n",
    "euro12.iloc[: , :7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns except the last 3\n",
    "\n",
    "euro12.iloc[: , :-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aecbe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presents/shows only the Shooting Accuracy from England, Italy and Russia\n",
    "# df.loc[df[\"Team\"].isin([\"England\", \"Italy\", \"Russia\"])][[\"Shooting Accuracy\"]]\n",
    "\n",
    "mask = euro12['Team'].isin(['England', 'Italy', 'Russia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b6423",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro12.loc[mask][['Team','Shooting Accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c438d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2577f2a",
   "metadata": {},
   "source": [
    "# Pandas - Assignment No 01\n",
    "- Click here to solve [Pandas - Assignment no 01](https://www.kaggle.com/code/ehtishamsadiq/pandas-assignment-no-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5084fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f768ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9953560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d092076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f380359b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2c4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6df26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        body {\n",
       "            background-color: #f2fff2;\n",
       "        }\n",
       "        h1 {\n",
       "            text-align: center;\n",
       "            font-weight: bold;\n",
       "            font-size: 36px;\n",
       "            color: #4295F4;\n",
       "            text-decoration: underline;\n",
       "            padding-top: 15px;\n",
       "        }\n",
       "        \n",
       "        h2 {\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            font-size: 30px;\n",
       "            color: #4A000A;\n",
       "            text-decoration: underline;\n",
       "            padding-top: 10px;\n",
       "        }\n",
       "        \n",
       "        h3 {\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            font-size: 30px;\n",
       "            color: #f0081e;\n",
       "            text-decoration: underline;\n",
       "            padding-top: 5px;\n",
       "        }\n",
       "\n",
       "        \n",
       "        p {\n",
       "            text-align: center;\n",
       "            font-size: 12 px;\n",
       "            color: #0B9923;\n",
       "        }\n",
       "    </style>\n",
       "\n",
       "<h1>Hello</h1>\n",
       "<p>Hello World</p>\n",
       "<h2> Hello</h2>\n",
       "<h3> World </h3>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "style = \"\"\"\n",
    "    <style>\n",
    "        body {\n",
    "            background-color: #f2fff2;\n",
    "        }\n",
    "        h1 {\n",
    "            text-align: center;\n",
    "            font-weight: bold;\n",
    "            font-size: 36px;\n",
    "            color: #4295F4;\n",
    "            text-decoration: underline;\n",
    "            padding-top: 15px;\n",
    "        }\n",
    "        \n",
    "        h2 {\n",
    "            text-align: left;\n",
    "            font-weight: bold;\n",
    "            font-size: 30px;\n",
    "            color: #4A000A;\n",
    "            text-decoration: underline;\n",
    "            padding-top: 10px;\n",
    "        }\n",
    "        \n",
    "        h3 {\n",
    "            text-align: left;\n",
    "            font-weight: bold;\n",
    "            font-size: 30px;\n",
    "            color: #f0081e;\n",
    "            text-decoration: underline;\n",
    "            padding-top: 5px;\n",
    "        }\n",
    "\n",
    "        \n",
    "        p {\n",
    "            text-align: center;\n",
    "            font-size: 12 px;\n",
    "            color: #0B9923;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\"\n",
    "\n",
    "html_content = \"\"\"\n",
    "<h1>Hello</h1>\n",
    "<p>Hello World</p>\n",
    "<h2> Hello</h2>\n",
    "<h3> World </h3>\n",
    "\"\"\"\n",
    "\n",
    "HTML(style + html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c8316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb2618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fd94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5644f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e956518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c461a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2db73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc6f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05f7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5b9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad1fcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cfaaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
