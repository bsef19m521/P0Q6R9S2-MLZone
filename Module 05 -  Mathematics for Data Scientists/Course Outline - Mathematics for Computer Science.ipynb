{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9041eff6",
   "metadata": {},
   "source": [
    "<h1 align='center'> Mathematics for Computer Science </h1>\n",
    "\n",
    "## MODULE 01: Linear Algebra\n",
    "\n",
    "### Chapter 01: Systems of Linear equations: two variables\n",
    "- Machine learning motivation\n",
    "- Systems of sentences\n",
    "- Systems of equations\n",
    "- Systems of equations as lines\n",
    "- A geometric notion of singularity\n",
    "- Singular vs nonsingular matrices\n",
    "- Linear dependence and independence\n",
    "- The determinant\n",
    "\n",
    "\n",
    "### Chapter 02: Systems of Linear Equations: three variables\n",
    "- Systems of equations (3×3)\n",
    "- Singular vs non-singular (3×3)\n",
    "- Systems of equations as planes (3×3)\n",
    "- Linear dependence and independence (3×3)\n",
    "- The determinant (3×3)\n",
    "\n",
    "### Chapter 03: Solving systems of Linear Equations: Elimination\n",
    "- Machine learning motivation\n",
    "- Solving non-singular systems of linear equations\n",
    "- Solving singular systems of linear equations\n",
    "- Solving systems of equations with more variables\n",
    "- Matrix row-reduction\n",
    "- Row operations that preserve singularity\n",
    "- Gaussian elimination\n",
    "\n",
    "### Chapter 04: Solving systems of Linear Equations: Row Echelon Form and Rank\n",
    "- The rank of a matrix\n",
    "- The rank of a matrix in general\n",
    "- Row echelon form\n",
    "- Row echelon form in general\n",
    "- Reduced row echelon form\n",
    "\n",
    "### Chapter 05: Vectors\n",
    "- Norm of a vector\n",
    "- Sum and difference of vectors\n",
    "- Distance between vectors\n",
    "- Multiplying a vector by a scalar\n",
    "- The dot product\n",
    "- Geometric Dot Product\n",
    "- Multiplying a matrix by a vector\n",
    "- **Assignment**: Vector Operations: Scalar Multiplication, Sum and Dot Product of Vectors\n",
    "\n",
    "### Chapter 06: Linear transformations\n",
    "- Matrices as linear transformations\n",
    "- Linear transformations as matrices\n",
    "- Matrix multiplication\n",
    "- The identity matrix\n",
    "- Matrix inverse\n",
    "- Which matrices have an inverse?\n",
    "- Neural networks and matrices\n",
    "\n",
    "### Chapter 07: Determinants In-depth\n",
    "- Machine Learning Motivation\n",
    "- Singularity and rank of linear transformation\n",
    "- Determinant as an area\n",
    "- Determinant of a product\n",
    "- Determinants of inverses\n",
    "\n",
    "### Chapter 08: Eigenvalues and Eigenvectors\n",
    "- Bases in Linear Algebra\n",
    "- Span in Linear Algebra\n",
    "- Interactive visualization: Linear Span\n",
    "- Eigenbases\n",
    "- Eigenvalues and eigenvectors\n",
    "- Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95e49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddcf04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba7f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac476f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70dd70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be050f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70931cc7",
   "metadata": {},
   "source": [
    "## MODULE 02: Probability & Statistics\n",
    "\n",
    "### Chapter 01: Introduction to probability\n",
    "- Concept of probability: repeated random trials\n",
    "- Conditional probability and independence \n",
    "- Discriminative learning and conditional probability\n",
    "- Bayes theorem \n",
    "\n",
    "### Chapter 02: Random variables\n",
    "- Random variables\n",
    "- Cumulative distribution function\n",
    "- Discrete random variables: Bernoulli distribution\n",
    "- Discrete random variables: Binomial distribution\n",
    "- Probability mass function\n",
    "- Continuous random variables: Uniform distribution \n",
    "- Continuous random variables: Gaussian distribution\n",
    "- Continuous random variables: Chi squared distribution\n",
    "- Probability distribution function\n",
    "\n",
    "### Chapter 03: Describing distributions\n",
    "- Measures of central tendency: mean, median, mode\n",
    "- Expected values\n",
    "- Quantiles and box-plots \n",
    "- Measures of dispersion: variance, standard deviation\n",
    "    \n",
    "### Chapter 04: Random vectors\n",
    "- Joint distributions\n",
    "- Marginal and conditional distributions\n",
    "- Independence\n",
    "- Measures of relatedness: covariance\n",
    "- Multivariate normal distribution\n",
    "\n",
    "\n",
    "### Chapter 05: Sampling and point estimates\n",
    "- Population vs. sample \n",
    "- Describing samples: sample proportion and sample mean\n",
    "- Distribution of sample mean and proportion: Central Limit Theorem \n",
    "- Point estimates\n",
    "- Biased vs Unbiased estimates \n",
    "\n",
    "### Chapter 06: Maximum likelihood estimation\n",
    "- ML motivation example: Linear Discriminant Analysis\n",
    "- Likelihood\n",
    "- Intuition behind maximum likelihood estimation\n",
    "- MLE: How to get the maximum using calculus\n",
    "    \n",
    "### Chapter 07: Bayesian statistics \n",
    "- ML motivation example: Naive Bayes\n",
    "- Frequentist vs. Bayesian statistics\n",
    "- A priori/ a posteriori distributions\n",
    "- Bayesian estimators: posterior mean, posterior median, MAP\n",
    "\n",
    "### Chapter 08: Confidence intervals\n",
    "- Margin of error\n",
    "- Interval estimation\n",
    "- Confidence Interval for mean of population\n",
    "- CI for parameters in linear regression\n",
    "- Prediction Interval\n",
    "\n",
    "### Chapter 09: Hypothesis testing\n",
    "- ML Motivation: AB Testing\n",
    "- Criminal trial\n",
    "- Two types of errors\n",
    "- Test for proportion and means\n",
    "- Two sample inference for difference between groups \n",
    "- ANOVA\n",
    "- Power of a test\n",
    "\n",
    "### Chapter 10: Simple Linear Regression\n",
    "- Variance and Standard Deviation\n",
    "- Covariance and Covariance Matrix\n",
    "- Correlation and Correlation Matrix\n",
    "- Regression\n",
    "- Regression Analysis\n",
    "- Linear Regression\n",
    "    - Fitting a Line using Gradiant Descent\n",
    "    - Fitting a Line using Linear Least Squares (with one feature)\n",
    "    \n",
    "## Bonus:\n",
    "\n",
    "- Recap\n",
    "    - Classical vs Emperical Probability\n",
    "    - Marginal/Simple/Unconditional Probability (with examples)\n",
    "    - Types of Events\n",
    "    - Joint Probability & Conditional Probability\n",
    "- Bayes' Theorem\n",
    "    - Proof of Bayes' Theorem\n",
    "    - Formulas of Bayes' Theorem\n",
    "    - Examples of Bayes' Theorem\n",
    "- Overview of Naïve Bayes' Classifier\n",
    "- Naïve Bayes' Classifier for Datasets with Discrete Input Features\n",
    "    - Example 1: Single Input FeatureExample \n",
    "    - 2: Multiple Input Features\n",
    "    - Example 3: Multiple Input Features\n",
    "    - Example 4: Using Naïve Bayes' on Text Data\n",
    "- Naïve Bayes' Classifier for Datasets with Continuous Input Features\n",
    "    - Example 1: Single Input Feature\n",
    "    - Example 2: Multiple Input Features\n",
    "\n",
    "**Assignments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9d033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95335a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b12a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf15d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d541cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5401039a",
   "metadata": {},
   "source": [
    "## MODULE 03: Calculus\n",
    "\n",
    "### Chapter 01: Introduction to Calculus, Functions and Limits\n",
    "- What is Calculus?\n",
    "- Functions and their implementation using Python\n",
    "- What Are Limits?\n",
    "- Precise Definition of Limit\n",
    "- Limit Laws \n",
    "- Infinities and Asymptotes \n",
    "- Indeterminate Forms \n",
    "- Limits in Python\n",
    "- Limits with Plotting in Python \n",
    "\n",
    "### Chapter 02: Derivatives\n",
    "- Example to motivate derivatives: Speedometer\n",
    "- Derivative of common functions (c, x, $x^2$, 1/x)\n",
    "- Meaning of e and the derivative of $e^x$\n",
    "- Derivative of log x\n",
    "- Existence of derivatives\n",
    "- Properties of derivative\n",
    "- Using Differentiation Rules to Differentiate a Function\n",
    "- Using First Principle to Differentiate a Function\n",
    "- Python Code to Differentiate a function using First Principle\n",
    "- Plotting the function and its derivative\n",
    "- How to Find Minima & Maxima using Derivatives?\n",
    "- Partial Derivatives and Gradient\n",
    "\n",
    "### Chapter 03: Optimization with derivatives\n",
    "- Intro to optimization\n",
    "- Optimizing cost functions in ML: Squared loss\n",
    "- Optimizing cost functions in ML: Log loss\n",
    "\n",
    "### Chapter 04: Gradients and optimization\n",
    "- Intro to gradients\n",
    "- Example to motivate gradients: Temperature\n",
    "- Gradient notation\n",
    "- Optimization using slope method: Linear regression\n",
    "\n",
    "### Chapter 05: Gradient Descent Algorithm\n",
    "- Mountain Analogy for Gradient Descent Algorithm\n",
    "- What is Gradient Descent and How to do Gradient Descent?\n",
    "- Gradient Descent in Python\n",
    "- Optimization using gradient descent: 1 variable\n",
    "- Optimization using gradient descent: 2 variable \n",
    "- Challenges of Gradient Descent Algorithm\n",
    "    - Local Minima and Unfortunate Starting Point\n",
    "    - Vanishing Gradient Problem\n",
    "    - Exploding Gradient Problem\n",
    "\n",
    "### Chapter 06: Gradient descent for linear regression\n",
    "- Recap of Linear Regression using OLS\n",
    "- Example (Simple Linear Regression using Gradient Descent)\n",
    "- Minimizing Error Function for Gradient Descent Algorithm\n",
    "- Partial Derivatives of Error Function\n",
    "- Calculate Regression Coefficients Using Gradient Descent Algorithm\n",
    "- Fit the Line\n",
    "- Carryout the Prediction\n",
    "\n",
    "### Chapter 07: Optimization in Neural Networks\n",
    "- What is a Single Layer Perceptron?\n",
    "- Perceptron with no activation and squared loss (linear regression)\n",
    "- Perceptron with sigmoid activation and log loss (classification)\n",
    "- Two-layer neural network with sigmoid activation and log loss\n",
    "- Mathematics of Backpropagation\n",
    "\n",
    "### Chapter 08: Beyond Gradient Descent: Newton’s Method\n",
    "- Root finding with Newton’s method\n",
    "- Adapting Newton’s method for optimization\n",
    "- Second derivatives and Hessians\n",
    "- Multivariate Newton’s method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe756aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e17b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0787d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded379bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef267de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665ffe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc72557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca3fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
